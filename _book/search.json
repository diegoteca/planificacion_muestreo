[
  {
    "objectID": "calibracion.html",
    "href": "calibracion.html",
    "title": "5  Calibración",
    "section": "",
    "text": "5.1 Calibración muestra azar simple\nLa estrategia de la calibración esta compuesta por un conjunto de prácticas que aspiran a lograr objetivos similares al proceso del balanceo del cubo pero con métodos cualitativamente diferentes. La principal diferencia radica en que la calibración se realiza ex-post la ejecución de la muestra (o sea, en el momento de la estimación) y no ex-ante (o sea, en el momento del diseño) (Deville y Tillé 2004, pag. 907). Esto es una diferencia fundamental que emparenta a la calibración con el enfoque del “Model Assisted” y la aleja del “Design Based”1. En efecto, tanto el balanceo como la calibración pueden considerarse prácticas relativamente generales que, en su interior, incluyen otras prácticas más específicas. Esto es lo que habilita a afirmar que, por ejemplo, la estratificación es un caso particular del balanceo así como la post-estratificación es un caso particular de la calibración (Y. Tillé 2011, pag. 223).\nOtra diferencia entre el balanceo y la calibración es que para realizar la calibración en algunas situaciones (esto depende de la técnica específica seleccionada) sólo es necesario los totales de la población y no, como en el balanceo, los valores de cada unidad que compone esa población.\nLas características anteriores hacen que el proceso de calibración sea muy útil en momentos en donde existe conocimientos sobre algunos totales de la población y no se haya podido controlar mucho el proceso de diseño de la muestra (p.e. diseños no probabilistas) o diseños probabilistas pero con una alta tasa de no respuesta. Estas características hacen al proceso de calibración algo muy deseado para muchas investigaciones contemporáneas en donde pueda admitirse que se conocen algunos parámetros poblacionales y, por ejemplo, se ha realizado una muestra que se difundió de manera virtual a través de un link que circuló por diferentes redes sociales. Esto deja en pie la discusión sobre que “tan buenos” podrán ser los resultados de esa investigación pero no parece haber muchas dudas que la investigación del ejemplo anterior será mejor si se le realiza un proceso de calibración mientras que será peor si no se realiza ese proceso.2\nEn cuanto a su pertinencia, siempre que haya disponibilidad de tiempo (y el saber necesario para realizarlo) es aconsejable realizar una calibración. Esto es cierto al menos porque el balanceo tiene el problema del redondeo (las muestras son muestras de números enteros) y la calibración no, ya que puede construirse calibradores con números racionales. Por esta misma razón, aún cuando se haya realizado una muestra con un diseño por balanceo, es recomendable calibrar con los totales de las variables que se usaron en el proceso de balanceo.\nDetalladas algunas diferencias entre la calibración y el balanceo ahora se pasa a diferenciar la calibración (de una muestra) de la imputación (de variables específicas).\nPor último, a veces se suele asimilar como sinónimos en término calibración con el término post-estratificación. Más arriba ya se había comentado que el segundo puede considerarse como un caso particular (aunque quizás el más difundido) del primero en donde sólo se utilizan variables categóricas (estratos) para el proceso de la calibración. Lo mismo puede afirmarse del método menos difundido del “raking” que permite la calibración de múltiples variables categóricas sin la necesidad de realizar cruces entre ellas con el riesgo de no tener casos en la muestra de algunas de las celdas de los múltiples cruces (Lumley 2010, pag. 139). Por esta razón, aquí usaremos directamente el método de la calibración por ser el más general ya que permite la inclusión tanto de variables categóricas como continuas y no presenta los riesgos de la post-calibración en cuanto a la posible ausencia de casos frutos de los cruces de las variables categóricas.\nA continuación vamos a trabajar con 2 ejemplos alternativos. Uno, en donde la calibración se realiza sobre la muestra aleatoria simple y otra que se realiza sobre la muestra balanceada y bien distribuida. En función de lo visto anteriormente (Sección 3.2, Sección 4.1 y ?sec-bien_distribuida) ya sabemos que ambas calibraciones van a partir desde un punto de inicio diferente. Veremos que tanta distancia entre sí y con respecto a los parámetros poblaciones van a tener los respectivos puntos de llegada (esto es, las estimaciones de ambas muestras) luego de realizar la calibración. En otras palabras, la muestra balanceada y bien distribuida ya se encontraba (en general) bastante cerca de los parámetros poblacionales por lo que, a priori, cuenta con alguna ventaja desde su puesto de largada.\nComenzaremos haciendo la calibración sobre nuestra muestra realizada por azar simple y su resultado lo comparemos con la respectiva muestra de azar simple (sin calibrar) y con los respectivos parámetros poblacionales. Vamos a ver que, en comparación con otras técnicas, la mayor flexibilidad de la calibración se paga con una mayor especificación de los parámetros de sus funciones3.\nCódigo\nlibrary(sampling)\nlibrary(survey)\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(here)\nlibrary(gtsummary)\nlibrary(janitor)\nlibrary(downloadthis)\nlibrary(gt)\n\ntheme_gtsummary_language(\nlanguage = \"es\",\ndecimal.mark = \",\",\nbig.mark = \".\")\nCódigo\nmuestra_bien_distribuida_sv = read_rds(here(\"Outputs\", \"muestra_bien_distribuida_sv.rds\"))\nmuestra_azar_simple_sv = read_rds(here(\"Outputs\", \"muestra_azar_simple_sv.rds\"))\nbase = read_rds(here(\"Outputs\", \"base.rds\"))\n\ntbl_azar_simple = read_rds(here(\"Outputs\", \"tbl_azar_simple.rds\"))\ntbl_bien_distribuida = read_rds(here(\"Outputs\", \"tbl_bien_distribuida.rds\"))\ntbl_pob_param = read_rds(here(\"Outputs\", \"tbl_pob_param.rds\"))\nPara eso vamos a recuperar el objeto con el cual le informábamos a R que habíamos realizado una muestra aleatoria simple (Sección 3.2). Ese va a ser nuestro primer insumo al cual le vamos a realizar la calibración y para eso es importante el proceso de la selección y armado de las covariables. Esta parte es similar en espíritu a lo realizado en el proceso de balanceo pero la parte operativa tiene pequeñas diferencias como se observa en el siguiente código.\nCódigo\nmuestra_azar_simple_sv = read_rds(here(\"Outputs\", \"muestra_azar_simple_sv.rds\"))\n\nbase = base |&gt;\nselect(clave, matricula, secciones, sondeo_primero, sondeo_segundo, region, ambito) \n\n# Calculo la cantidad de casos de la población\n\nN = nrow(base)\n\n# Los totales poblacionales son especificados como una matriz (no como un vector o como un dataframe) en función del modelo o fórmula especificada en el parámetro \"formula\" de la función calibrate de la librería survey\n\ntotals = unlist(c(nrow(base),\n           sum(base$matricula, na.rm = TRUE),\n           count(base[base$ambito == \"Rural Disperso\", ]),\n           count(base[base$ambito == \"Rural Agrupado\", ]),\n           count(base[base$region == \"02\", ]),\n           count(base[base$region == \"03\", ]),\n           count(base[base$region == \"04\", ]),\n           count(base[base$region == \"05\", ]),\n           count(base[base$region == \"06\", ]),\n           count(base[base$region == \"07\", ]),\n           count(base[base$region == \"08\", ]),\n           count(base[base$region == \"09\", ]),\n           count(base[base$region == \"10\", ]),\n           count(base[base$region == \"11\", ]),\n           count(base[base$region == \"12\", ]),\n           count(base[base$region == \"13\", ]),\n           count(base[base$region == \"14\", ]),\n           count(base[base$region == \"15\", ]),\n           count(base[base$region == \"16\", ]),\n           count(base[base$region == \"17\", ]),\n           count(base[base$region == \"18\", ]),\n           count(base[base$region == \"19\", ]),\n           count(base[base$region == \"20\", ]),\n           count(base[base$region == \"21\", ]),\n           count(base[base$region == \"22\", ]),\n           count(base[base$region == \"23\", ]),\n           count(base[base$region == \"24\", ]),\n           count(base[base$region == \"25\", ])))\n\n# Las totales de las variables numerícas son más fáciles de agregar a la matrix porque alcanza con sumarlos. En cambio Llos totales de las variables categóricas es algo más difícil porque hay que hacer los totales para cada categoría. En este sentido, no es lo mismo hacer una calibración para 3 categorías como \"Ambito\" que para más de 20 como \"Región\". Al igual que muchas otras funciones (p.e. regresiones) cuando se trabaja con categorías se deja la primera afuera para actúe de intercepto. En este ejemplo Ámbito \"Urbano\" y Región \"1\" no están presentes.\n\nmuestra_azar_simple_cal = \ncalibrate(muestra_azar_simple_sv,\n          formula = ~ matricula + ambito + region,\n          population = totals,\n          calfun = \"linear\")\n\n\nSample:  [1] \"(Intercept)\"          \"matricula\"            \"ambitoRural Disperso\"\n [4] \"ambitoRural Agrupado\" \"region02\"             \"region03\"            \n [7] \"region04\"             \"region05\"             \"region06\"            \n[10] \"region07\"             \"region08\"             \"region09\"            \n[13] \"region10\"             \"region11\"             \"region12\"            \n[16] \"region13\"             \"region14\"             \"region15\"            \n[19] \"region16\"             \"region17\"             \"region18\"            \n[22] \"region19\"             \"region20\"             \"region21\"            \n[25] \"region22\"             \"region23\"             \"region24\"            \n[28] \"region25\"            \nPopltn:  [1] \"\"  \"\"  \"n\" \"n\" \"n\" \"n\" \"n\" \"n\" \"n\" \"n\" \"n\" \"n\" \"n\" \"n\" \"n\" \"n\" \"n\" \"n\" \"n\"\n[20] \"n\" \"n\" \"n\" \"n\" \"n\" \"n\" \"n\" \"n\" \"n\"\n\n\nCódigo\ntbl_azar_simple_cal = muestra_azar_simple_cal |&gt;\ntbl_svysummary(\ninclude = c(matricula, secciones, sondeo_primero, sondeo_segundo, region, ambito),\ndigits = list(deff = label_style_number(digits = 3),\n              sd = label_style_number(digits = 3)),\nstatistic = list(all_continuous() ~ \"{mean} ({mean.std.error})\",\n                all_categorical() ~ \"{p}% (n={n_unweighted})\")) |&gt;\nadd_ci() \n\ntbl_comp_azar_simple_cal = \ntbl_merge(tbls = list(tbl_azar_simple_cal, tbl_azar_simple, tbl_pob_param), \n          tab_spanner = c(\"AS Calibrado\",\"AS sin calibrar\",\"Poblacion\"))\n\ntbl_comp_azar_simple_cal\n\n\n\n\nTabla 5.1: Calibración muestra azar simple\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaracterística\n\nAS Calibrado\n\n\nAS sin calibrar\n\n\nPoblacion\n\n\n\nN = 4.1681\n95% CI2\nN = 4.1681\n95% CI2\nN = 4.1683\n\n\n\n\nmatricula\n267 (0)\n267, 267\n276,6 (2,9)\n271, 282\n267,9\n\n\n    Desconocido\n\n\n\n\n\n\n\n\n9\n\n\nsecciones\n11 (0)\n11, 11\n11,6 (0,1)\n11, 12\n11,2\n\n\n    Desconocido\n\n\n\n\n\n\n\n\n9\n\n\nsondeo_primero\n57 (0)\n56, 57\n56,2 (0,2)\n56, 57\n57,3\n\n\n    Desconocido\n568\n\n\n472\n\n\n560\n\n\nsondeo_segundo\n70 (0)\n69, 70\n69,8 (0,2)\n69, 70\n69,5\n\n\n    Desconocido\n647\n\n\n556\n\n\n570\n\n\nregion\n\n\n\n\n\n\n\n\n\n\n\n\n    01\n4,5% (n=7)\n4,5%, 4,5%\n2,3% (n=7)\n2,0%, 2,7%\n4,5% (189)\n\n\n    02\n5,4% (n=19)\n5,4%, 5,4%\n6,3% (n=19)\n5,8%, 6,9%\n5,4% (223)\n\n\n    03\n5,0% (n=16)\n5,0%, 5,0%\n5,3% (n=16)\n4,9%, 5,8%\n5,0% (210)\n\n\n    04\n5,1% (n=21)\n5,1%, 5,1%\n7,0% (n=21)\n6,5%, 7,6%\n5,1% (213)\n\n\n    05\n4,7% (n=8)\n4,7%, 4,7%\n2,7% (n=8)\n2,3%, 3,0%\n4,7% (194)\n\n\n    06\n3,6% (n=11)\n3,6%, 3,6%\n3,7% (n=11)\n3,3%, 4,1%\n3,6% (148)\n\n\n    07\n3,3% (n=11)\n3,3%, 3,3%\n3,7% (n=11)\n3,3%, 4,1%\n3,3% (138)\n\n\n    08\n3,6% (n=16)\n3,6%, 3,6%\n5,3% (n=16)\n4,9%, 5,8%\n3,6% (149)\n\n\n    09\n4,9% (n=20)\n4,9%, 4,9%\n6,7% (n=20)\n6,1%, 7,2%\n4,9% (205)\n\n\n    10\n5,4% (n=20)\n5,4%, 5,4%\n6,7% (n=20)\n6,1%, 7,2%\n5,4% (224)\n\n\n    11\n4,0% (n=13)\n4,0%, 4,0%\n4,3% (n=13)\n3,9%, 4,8%\n4,0% (166)\n\n\n    12\n3,7% (n=7)\n3,7%, 3,7%\n2,3% (n=7)\n2,0%, 2,7%\n3,7% (155)\n\n\n    13\n3,1% (n=8)\n3,1%, 3,1%\n2,7% (n=8)\n2,3%, 3,0%\n3,1% (131)\n\n\n    14\n4,1% (n=12)\n4,1%, 4,1%\n4,0% (n=12)\n3,6%, 4,4%\n4,1% (169)\n\n\n    15\n4,2% (n=10)\n4,2%, 4,2%\n3,3% (n=10)\n3,0%, 3,7%\n4,2% (174)\n\n\n    16\n3,0% (n=6)\n3,0%, 3,0%\n2,0% (n=6)\n1,7%, 2,3%\n3,0% (125)\n\n\n    17\n3,2% (n=10)\n3,2%, 3,2%\n3,3% (n=10)\n3,0%, 3,7%\n3,2% (133)\n\n\n    18\n3,8% (n=9)\n3,8%, 3,8%\n3,0% (n=9)\n2,7%, 3,4%\n3,8% (160)\n\n\n    19\n2,8% (n=8)\n2,8%, 2,8%\n2,7% (n=8)\n2,3%, 3,0%\n2,8% (118)\n\n\n    20\n3,8% (n=11)\n3,8%, 3,8%\n3,7% (n=11)\n3,3%, 4,1%\n3,8% (159)\n\n\n    21\n2,8% (n=6)\n2,8%, 2,8%\n2,0% (n=6)\n1,7%, 2,3%\n2,8% (117)\n\n\n    22\n3,7% (n=12)\n3,7%, 3,7%\n4,0% (n=12)\n3,6%, 4,4%\n3,7% (153)\n\n\n    23\n3,7% (n=14)\n3,7%, 3,7%\n4,7% (n=14)\n4,2%, 5,1%\n3,7% (153)\n\n\n    24\n4,7% (n=9)\n4,7%, 4,7%\n3,0% (n=9)\n2,7%, 3,4%\n4,7% (196)\n\n\n    25\n4,0% (n=16)\n4,0%, 4,0%\n5,3% (n=16)\n4,9%, 5,8%\n4,0% (166)\n\n\nambito\n\n\n\n\n\n\n\n\n\n\n\n\n    Urbano\n65% (n=201)\n65%, 65%\n67,0% (n=201)\n66%, 68%\n65,4% (2.727)\n\n\n    Rural Disperso\n26% (n=61)\n26%, 26%\n20,3% (n=61)\n19%, 21%\n25,7% (1.073)\n\n\n    Rural Agrupado\n8,8% (n=38)\n8,8%, 8,8%\n12,7% (n=38)\n12%, 13%\n8,8% (368)\n\n\n\n1 Media (SE); % (n=n (unweighted))\n\n\n2 CI = Intervalo de confianza\n\n\n3 Media; % (n)\nComo puede observarse en Tabla 5.1 la calibración ha mejorado sensiblemente la muestra de azar simple en casi todas las variables, aún en aquellas que no se usaron activamente en la matriz de calibración. En efecto, en la mayoría de las variables los valores de la muestra calibrada se acercan mucho a los parámetros poblacionales.\nUn paso adicional que se puede realizar si luego se quiere trabajar en una planilla de cálculo o, más en general, por fuera de R, es agregar los respectivos ponderadores del proceso de calibración al objeto para así tenerlos como una variable más. En este sentido, la base de datos con los casos seleccionados de la muestras ahora pasaría a tener 2 variables especiales que servirían para el proceso de expansión de la muestra a la población. Uno, un ponderador que ya existía luego de haber realizado el azar simple (y que era igual para todos los casos) y otro recientemente agregado, el calibrador, que es específico para cada caso.\nCódigo\ncal_weight = weights(muestra_azar_simple_cal) |&gt;\nas_tibble() |&gt;\nrename(cal_weight = value)\n\nbase_muestra_AS_cal = \nbind_cols(as_tibble(muestra_azar_simple_cal), cal_weight) |&gt;\nrename(pond_weight = pw)\n\ndownload_this(base_muestra_AS_cal,\n              output_name = \"base_muestra_AS_cal\",\n              output_extension = \".xlsx\",\n              button_label = \"Descargar Base\")\n\n\n Descargar Base\nTabla 5.2: Ponderadores y calibradores. Base muestra Azar simple.\n\n\n\nCódigo\nbase_muestra_AS_cal = base_muestra_AS_cal |&gt;\nselect(matricula, secciones, ambito, sondeo_primero, sondeo_segundo, pond_weight, cal_weight) |&gt;\ngt()",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Calibración</span>"
    ]
  },
  {
    "objectID": "calibracion.html#sec-cal_bien_distribuida",
    "href": "calibracion.html#sec-cal_bien_distribuida",
    "title": "5  Calibración",
    "section": "5.2 Calibración muestra bien distribuida",
    "text": "5.2 Calibración muestra bien distribuida\nEn el caso de la calibración de la muestra bien distribuida el proceso de calibración es similar con la diferencia que cambia el insumo al cual se le realiza la calibración. Aquí el código es un poco más simple porque se reutiliza la matriz de covariables construida para la calibración de la muestra de azar simple.\n\n\nCódigo\nmuestra_bien_distribuida_cal = \ncalibrate(muestra_bien_distribuida_sv,\n          formula = ~ matricula + ambito + region,\n          population = totals,\n          calfun = \"linear\")\n\n\nSample:  [1] \"(Intercept)\"          \"matricula\"            \"ambitoRural Disperso\"\n [4] \"ambitoRural Agrupado\" \"region02\"             \"region03\"            \n [7] \"region04\"             \"region05\"             \"region06\"            \n[10] \"region07\"             \"region08\"             \"region09\"            \n[13] \"region10\"             \"region11\"             \"region12\"            \n[16] \"region13\"             \"region14\"             \"region15\"            \n[19] \"region16\"             \"region17\"             \"region18\"            \n[22] \"region19\"             \"region20\"             \"region21\"            \n[25] \"region22\"             \"region23\"             \"region24\"            \n[28] \"region25\"            \nPopltn:  [1] \"\"  \"\"  \"n\" \"n\" \"n\" \"n\" \"n\" \"n\" \"n\" \"n\" \"n\" \"n\" \"n\" \"n\" \"n\" \"n\" \"n\" \"n\" \"n\"\n[20] \"n\" \"n\" \"n\" \"n\" \"n\" \"n\" \"n\" \"n\" \"n\"\n\n\nCódigo\ntbl_bien_distribuida_cal = muestra_bien_distribuida_cal |&gt;\ntbl_svysummary(\ninclude = c(matricula, secciones, sondeo_primero, sondeo_segundo, region, ambito),\ndigits = list(deff = label_style_number(digits = 3),\n              sd = label_style_number(digits = 3)),\nstatistic = list(all_continuous() ~ \"{mean} ({mean.std.error})\",\n                all_categorical() ~ \"{p}% (n={n_unweighted})\")) |&gt;\nadd_ci() \n\n\ntbl_comp_bien_distribuida_cal = \ntbl_merge(tbls = list(tbl_bien_distribuida_cal, tbl_bien_distribuida, tbl_pob_param), \ntab_spanner = c(\"BD calibrado\",\"BD sin calibrar\",\"Poblacion\"))\n\ntbl_comp_bien_distribuida_cal\n\n\n\n\nTabla 5.3: Calibración muestra bien distribuida\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaracterística\n\nBD calibrado\n\n\nBD sin calibrar\n\n\nPoblacion\n\n\n\nN = 4.1681\n95% CI2\nN = 4.1563\n95% CI2\nN = 4.1684\n\n\n\n\nmatricula\n267 (0)\n267, 267\n268 (3)\n262, 274\n267,9\n\n\n    Desconocido\n\n\n\n\n\n\n\n\n9\n\n\nsecciones\n11 (0)\n11, 11\n11 (0)\n11, 11\n11,2\n\n\n    Desconocido\n\n\n\n\n\n\n\n\n9\n\n\nsondeo_primero\n58 (0)\n58, 58\n58 (0)\n58, 58\n57,3\n\n\n    Desconocido\n478\n\n\n485\n\n\n560\n\n\nsondeo_segundo\n69 (0)\n68, 69\n68 (0)\n68, 69\n69,5\n\n\n    Desconocido\n543\n\n\n554\n\n\n570\n\n\nregion\n\n\n\n\n\n\n\n\n\n\n\n\n    01\n4,5% (n=13)\n4,5%, 4,5%\n4,3% (n=13)\n3,9%, 4,8%\n4,5% (189)\n\n\n    02\n5,4% (n=17)\n5,4%, 5,4%\n5,7% (n=17)\n5,2%, 6,2%\n5,4% (223)\n\n\n    03\n5,0% (n=15)\n5,0%, 5,0%\n5,0% (n=15)\n4,5%, 5,5%\n5,0% (210)\n\n\n    04\n5,1% (n=15)\n5,1%, 5,1%\n5,0% (n=15)\n4,5%, 5,5%\n5,1% (213)\n\n\n    05\n4,7% (n=13)\n4,7%, 4,7%\n4,3% (n=13)\n3,9%, 4,8%\n4,7% (194)\n\n\n    06\n3,6% (n=11)\n3,6%, 3,6%\n3,7% (n=11)\n3,3%, 4,1%\n3,6% (148)\n\n\n    07\n3,3% (n=10)\n3,3%, 3,3%\n3,3% (n=10)\n3,0%, 3,7%\n3,3% (138)\n\n\n    08\n3,6% (n=11)\n3,6%, 3,6%\n3,7% (n=11)\n3,3%, 4,1%\n3,6% (149)\n\n\n    09\n4,9% (n=16)\n4,9%, 4,9%\n5,3% (n=16)\n4,9%, 5,8%\n4,9% (205)\n\n\n    10\n5,4% (n=16)\n5,4%, 5,4%\n5,3% (n=16)\n4,9%, 5,8%\n5,4% (224)\n\n\n    11\n4,0% (n=11)\n4,0%, 4,0%\n3,7% (n=11)\n3,3%, 4,1%\n4,0% (166)\n\n\n    12\n3,7% (n=12)\n3,7%, 3,7%\n4,0% (n=12)\n3,6%, 4,4%\n3,7% (155)\n\n\n    13\n3,1% (n=8)\n3,1%, 3,1%\n2,7% (n=8)\n2,3%, 3,0%\n3,1% (131)\n\n\n    14\n4,1% (n=11)\n4,1%, 4,1%\n3,7% (n=11)\n3,3%, 4,1%\n4,1% (169)\n\n\n    15\n4,2% (n=15)\n4,2%, 4,2%\n5,0% (n=15)\n4,5%, 5,5%\n4,2% (174)\n\n\n    16\n3,0% (n=7)\n3,0%, 3,0%\n2,3% (n=7)\n2,0%, 2,7%\n3,0% (125)\n\n\n    17\n3,2% (n=11)\n3,2%, 3,2%\n3,7% (n=11)\n3,3%, 4,1%\n3,2% (133)\n\n\n    18\n3,8% (n=11)\n3,8%, 3,8%\n3,7% (n=11)\n3,3%, 4,1%\n3,8% (160)\n\n\n    19\n2,8% (n=9)\n2,8%, 2,8%\n3,0% (n=9)\n2,6%, 3,4%\n2,8% (118)\n\n\n    20\n3,8% (n=10)\n3,8%, 3,8%\n3,3% (n=10)\n3,0%, 3,7%\n3,8% (159)\n\n\n    21\n2,8% (n=10)\n2,8%, 2,8%\n3,3% (n=10)\n3,0%, 3,7%\n2,8% (117)\n\n\n    22\n3,7% (n=12)\n3,7%, 3,7%\n4,0% (n=12)\n3,6%, 4,4%\n3,7% (153)\n\n\n    23\n3,7% (n=12)\n3,7%, 3,7%\n4,0% (n=12)\n3,6%, 4,4%\n3,7% (153)\n\n\n    24\n4,7% (n=14)\n4,7%, 4,7%\n4,7% (n=14)\n4,2%, 5,1%\n4,7% (196)\n\n\n    25\n4,0% (n=10)\n4,0%, 4,0%\n3,3% (n=10)\n3,0%, 3,7%\n4,0% (166)\n\n\nambito\n\n\n\n\n\n\n\n\n\n\n\n\n    Urbano\n65% (n=195)\n65%, 65%\n65% (n=195)\n64%, 66%\n65,4% (2.727)\n\n\n    Rural Disperso\n26% (n=80)\n26%, 26%\n27% (n=80)\n26%, 28%\n25,7% (1.073)\n\n\n    Rural Agrupado\n8,8% (n=25)\n8,8%, 8,8%\n8,3% (n=25)\n7,8%, 9,0%\n8,8% (368)\n\n\n\n1 Media (SE); % (n=n (unweighted))\n\n\n2 CI = Intervalo de confianza\n\n\n3 Media (DE); % (n sin ponderar)\n\n\n4 Media; % (n)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCódigo\ncal_weight = weights(muestra_azar_simple_cal) |&gt;\nas_tibble() |&gt;\nrename(cal_weight = value)\n\nbase_muestra_BD_cal = \nbind_cols(as_tibble(muestra_bien_distribuida_cal), cal_weight) |&gt;\nrename(pond_weight = pw)\n\ndownload_this(base_muestra_BD_cal,\n              output_name = \"base_muestra_BD_cal\",\n              output_extension = \".xlsx\",\n              button_label = \"Descargar Base\")\n\n\n Descargar Base\n\n\nAl igual que con la calibración de la base de la muestra de azar simple, aquí vamos a extraer los calibradores para luego agregarlos a la base de datos.\n\n\nCódigo\ncal_weight = weights(muestra_bien_distribuida_cal) |&gt;\nas_tibble() |&gt;\nrename(cal_weight = value)\n\nbase_muestra_BD_cal = \nbind_cols(as_tibble(muestra_bien_distribuida_cal), cal_weight) |&gt;\nrename(pond_weight = pw)\n\ndownload_this(base_muestra_BD_cal,\n              output_name = \"base_muestra_BD_cal\",\n              output_extension = \".xlsx\",\n              button_label = \"Descargar Base\")\n\n\n Descargar Base\n\n\nEs interesante destacar, como se observa en la Tabla 5.4 (y a diferencia de lo visto en la Tabla 5.1) que acá no sólo los calibradores son diferentes entre sí sino que también lo eran ponderadores de la muestra bien distribuida.\n\n\n\nTabla 5.4: Ponderadores y calibradores. Base muestra bien distribuida.\n\n\n\nCódigo\nbase_muestra_BD_cal = base_muestra_BD_cal |&gt;\nselect(matricula, secciones, ambito, sondeo_primero, sondeo_segundo, pond_weight, cal_weight) |&gt;\ngt()",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Calibración</span>"
    ]
  },
  {
    "objectID": "calibracion.html#comparación-calibración-muestra-balanceada-y-azar-simple",
    "href": "calibracion.html#comparación-calibración-muestra-balanceada-y-azar-simple",
    "title": "5  Calibración",
    "section": "5.3 Comparación calibración muestra balanceada y azar simple",
    "text": "5.3 Comparación calibración muestra balanceada y azar simple\nFinalmente vamos a realizar una comparación entre los resultados de los procesos de calibración antes realizados y los respectivos parámetros poblacionales. Esto es lo que precisamente se observa en la Tabla 5.5.\n\n\nCódigo\ntbl_comp_calibracion = tbl_merge(\ntbls = list(tbl_bien_distribuida_cal, tbl_azar_simple_cal, tbl_pob_param), \ntab_spanner = c(\"BD calibrado\",\"AS calibrado\",\"Poblacion\"))\n\ntbl_comp_calibracion\n\n\n\n\nTabla 5.5: Comparación entre calibración de las muestras bien distribuidas, de azar simple y los respectivos parámetros poblacionales\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaracterística\n\nBD calibrado\n\n\nAS calibrado\n\n\nPoblacion\n\n\n\nN = 4.1681\n95% CI2\nN = 4.1681\n95% CI2\nN = 4.1683\n\n\n\n\nmatricula\n267 (0)\n267, 267\n267 (0)\n267, 267\n267,9\n\n\n    Desconocido\n\n\n\n\n\n\n\n\n9\n\n\nsecciones\n11 (0)\n11, 11\n11 (0)\n11, 11\n11,2\n\n\n    Desconocido\n\n\n\n\n\n\n\n\n9\n\n\nsondeo_primero\n58 (0)\n58, 58\n57 (0)\n56, 57\n57,3\n\n\n    Desconocido\n478\n\n\n568\n\n\n560\n\n\nsondeo_segundo\n69 (0)\n68, 69\n70 (0)\n69, 70\n69,5\n\n\n    Desconocido\n543\n\n\n647\n\n\n570\n\n\nregion\n\n\n\n\n\n\n\n\n\n\n\n\n    01\n4,5% (n=13)\n4,5%, 4,5%\n4,5% (n=7)\n4,5%, 4,5%\n4,5% (189)\n\n\n    02\n5,4% (n=17)\n5,4%, 5,4%\n5,4% (n=19)\n5,4%, 5,4%\n5,4% (223)\n\n\n    03\n5,0% (n=15)\n5,0%, 5,0%\n5,0% (n=16)\n5,0%, 5,0%\n5,0% (210)\n\n\n    04\n5,1% (n=15)\n5,1%, 5,1%\n5,1% (n=21)\n5,1%, 5,1%\n5,1% (213)\n\n\n    05\n4,7% (n=13)\n4,7%, 4,7%\n4,7% (n=8)\n4,7%, 4,7%\n4,7% (194)\n\n\n    06\n3,6% (n=11)\n3,6%, 3,6%\n3,6% (n=11)\n3,6%, 3,6%\n3,6% (148)\n\n\n    07\n3,3% (n=10)\n3,3%, 3,3%\n3,3% (n=11)\n3,3%, 3,3%\n3,3% (138)\n\n\n    08\n3,6% (n=11)\n3,6%, 3,6%\n3,6% (n=16)\n3,6%, 3,6%\n3,6% (149)\n\n\n    09\n4,9% (n=16)\n4,9%, 4,9%\n4,9% (n=20)\n4,9%, 4,9%\n4,9% (205)\n\n\n    10\n5,4% (n=16)\n5,4%, 5,4%\n5,4% (n=20)\n5,4%, 5,4%\n5,4% (224)\n\n\n    11\n4,0% (n=11)\n4,0%, 4,0%\n4,0% (n=13)\n4,0%, 4,0%\n4,0% (166)\n\n\n    12\n3,7% (n=12)\n3,7%, 3,7%\n3,7% (n=7)\n3,7%, 3,7%\n3,7% (155)\n\n\n    13\n3,1% (n=8)\n3,1%, 3,1%\n3,1% (n=8)\n3,1%, 3,1%\n3,1% (131)\n\n\n    14\n4,1% (n=11)\n4,1%, 4,1%\n4,1% (n=12)\n4,1%, 4,1%\n4,1% (169)\n\n\n    15\n4,2% (n=15)\n4,2%, 4,2%\n4,2% (n=10)\n4,2%, 4,2%\n4,2% (174)\n\n\n    16\n3,0% (n=7)\n3,0%, 3,0%\n3,0% (n=6)\n3,0%, 3,0%\n3,0% (125)\n\n\n    17\n3,2% (n=11)\n3,2%, 3,2%\n3,2% (n=10)\n3,2%, 3,2%\n3,2% (133)\n\n\n    18\n3,8% (n=11)\n3,8%, 3,8%\n3,8% (n=9)\n3,8%, 3,8%\n3,8% (160)\n\n\n    19\n2,8% (n=9)\n2,8%, 2,8%\n2,8% (n=8)\n2,8%, 2,8%\n2,8% (118)\n\n\n    20\n3,8% (n=10)\n3,8%, 3,8%\n3,8% (n=11)\n3,8%, 3,8%\n3,8% (159)\n\n\n    21\n2,8% (n=10)\n2,8%, 2,8%\n2,8% (n=6)\n2,8%, 2,8%\n2,8% (117)\n\n\n    22\n3,7% (n=12)\n3,7%, 3,7%\n3,7% (n=12)\n3,7%, 3,7%\n3,7% (153)\n\n\n    23\n3,7% (n=12)\n3,7%, 3,7%\n3,7% (n=14)\n3,7%, 3,7%\n3,7% (153)\n\n\n    24\n4,7% (n=14)\n4,7%, 4,7%\n4,7% (n=9)\n4,7%, 4,7%\n4,7% (196)\n\n\n    25\n4,0% (n=10)\n4,0%, 4,0%\n4,0% (n=16)\n4,0%, 4,0%\n4,0% (166)\n\n\nambito\n\n\n\n\n\n\n\n\n\n\n\n\n    Urbano\n65% (n=195)\n65%, 65%\n65% (n=201)\n65%, 65%\n65,4% (2.727)\n\n\n    Rural Disperso\n26% (n=80)\n26%, 26%\n26% (n=61)\n26%, 26%\n25,7% (1.073)\n\n\n    Rural Agrupado\n8,8% (n=25)\n8,8%, 8,8%\n8,8% (n=38)\n8,8%, 8,8%\n8,8% (368)\n\n\n\n1 Media (SE); % (n=n (unweighted))\n\n\n2 CI = Intervalo de confianza\n\n\n3 Media; % (n)\n\n\n\n\n\n\n\n\n\n\n\nEn la Tabla 5.5 puede observarse como ambas estrategias de calibración parecen igual de eficaces ya que ambas arrojan resultados muy similares entre sí y, a su vez, muy similares con los parámetros poblacionales. En este contexto se recuerda que, si bien los valores finales son muy similares, la mejora realizada en el proceso de calibración es mayor sobre el diseño de azar simple ya que esa muestra no era tan precisa como la muestra bien distribuida y, por lo tanto, existía la oportunidad de mejorar bastante.\n\n\n\n\n\n\nDeville, Jean, y Yves Tillé. 2004. «Efficient balanced sampling: The cube method». Biometrika 91 (4): 893-912.\n\n\nElliott, Michael, y Richard Valliant. 2017. «Inference for nonprobability samples». Statistical Science 32 (2): 249-64.\n\n\nLumley, Thomas. 2010. Complex surveys. A guide to analysis using R. New Jersey: John Wiley & Sons.\n\n\nLundström, Sixten, y Carl Erik Särndal. 2009. «Calibration of weights in surveys with nonresponse and frame imperfections», enero.\n\n\nTillé, Ives. 2010. «Balanced sampling by means of the cube method».\n\n\nTillé, Yves. 2011. «Ten years of balanced sampling with the cube method: An appraisal». Survey Methodology 37 (2): 215-26.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Calibración</span>"
    ]
  },
  {
    "objectID": "calibracion.html#footnotes",
    "href": "calibracion.html#footnotes",
    "title": "5  Calibración",
    "section": "",
    "text": "En cambio el balanceo, si bien en su origen tiene una fuerte vinculación con el enfoque del “Model Assisted”, no se encuentra tan alejado del “design based” dado que el algoritmo del cubo selecciona muestras balanceadas dentro del conjunto de muestras aleatorias (I. Tillé 2010, pag. 39).↩︎\nEste tipo de discusiones ha enfrentado (y por ahora continua enfrentando) a los representantes de los enfoques de la “design based sample” y del “model assisted”. Los primeros suelen dudar de los beneficios de aplicar la calibración sobre diseños no probabilísticos aunque no suelen tener objeciones cuando la calibración se realiza sobre diseños probabilísticos (Elliott y Valliant 2017). En el fondo lo que está en juego son los grados de garantía que ofrece cada técnicas acerca de la representatividad no sólo sobre las heterogeneidades observables (algo mantenido por ambos enfoques) sino también sobre las heterogeneidades no observables (algo históricamente mantenido por el enfoque de la “design”).↩︎\nEn otras palabras, si ya se sabe de antemano que se va a realizar una post-estratificación es más simple utilizar una función específica para post-estratificar (p.e. la función “poststratify” de la librería survey o “poststrata” de la librería sampling).↩︎",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Calibración</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "6  Referencias Bibliográficas",
    "section": "",
    "text": "Baker, Reg, Michael Brick, Nancy Bates, Mike Battaglia, Mick Couper,\nJill Dever, Krista Gile, and Roger Tourangeau. 2013. “Report of\nthe AAPOR Task Force on Non-Probability Sampling.”\n\n\nBrus, Dick. 2022. Spatial Sampling with r. Boca Raton: Chapman\n& Hall /CRC.\n\n\nBunge, M. 1974. Semantics. Dordrecht. Reidel.\n\n\nCampbell, Donald, and Julian Stanley. 1963. Experimental and\nQuasi-Experimental Designs for Research. Boston: Houghton Mifflin\nCompany.\n\n\nDeville, Jean, and Yves Tillé. 2004. “Efficient Balanced Sampling:\nThe Cube Method.” Biometrika 91 (4): 893–912.\n\n\nElliott, Michael, and Richard Valliant. 2017. “Inference for\nNonprobability Samples.” Statistical Science 32 (2):\n249–64.\n\n\nFienberg, Stephen, and Judith Tanur. 1988. “From the Inside Out\nand the Outside in: Combining Experimental and Sampling\nStructures.” The Canadian Journal of Statistics 16 (2):\n135–51.\n\n\nGigerenzer, Gerd, Zeno Swijtink, Theodore Porter, John Beatty, and\nLorenz Krüger. 1997. The Empire of Chance. Cambridge: Cambridge\nUniversity Press.\n\n\nHacking, Ian. (1990) 2004. The Taming of Chance. Cambridge:\nCambridge University Press.\n\n\n———. 2006. The Emergence of Probability: A Philosophical Study of\nEarly Ideas about Probability, Induction and Statistical Inference.\nCambridge: Cambridge University Press.\n\n\nHedlin, Dan. 2015. “Why Are Design in Survey Sampling Ad Design of\nRandomised Experiments Separate Areas of Statistical Science?”\n\n\nKish, Leslie. 1980. “Design and Estimations for Domains.”\nThe Statistician 29 (4): 209–22.\n\n\n———. 1987. Statistical Design for Research. New Jersey: John\nWiley.\n\n\nKlima, Gyula. 2022. “The Medieval Problem of Universals.”\nIn, edited by Edward Zalta, Spring 2022. Stanford University.\n\n\nLumley, Thomas. 2010. Complex Surveys. A Guide to Analysis Using\nr. New Jersey: John Wiley & Sons.\n\n\nLundström, Sixten, and Carl Erik Särndal. 2009. “Calibration of\nWeights in Surveys with Nonresponse and Frame Imperfections,”\nJanuary.\n\n\nMorgan, Stephen, and Christopher Winship. 2015. Counterfactuals and\nCausal Inference. Second Edition. Cambridge: Cambridge University\nPress.\n\n\nNeyman, Jerzy. 1934. “On the Two Different Aspects of the\nRepresentative Method: The Method of Stratified Sampling and the Method\nof Purposive Selection.” Journal of the Royal Statistical\nSociety 97 (4): 558–625.\n\n\nPearl, J. 2018. The Book of Why. New York. Basic Books.\n\n\nPlatón. 2002 [370AVC]. Phaedrus. Oxford: Oxford University\nPress.\n\n\nSchneider, Ben. 2024. “Simulation-Based Variance Estimation for\nthe Cube Method.” https://www.practicalsignificance.com/posts/cube-method-simulating-joint-probs/.\n\n\nTillé, Ives. 2010. “Balanced Sampling by Means of the Cube\nMethod.”\n\n\nTillé, Yves. 2011. “Ten Years of Balanced Sampling with the Cube\nMethod: An Appraisal.” Survey Methodology 37 (2):\n215–26.\n\n\nTillé, Yves, and Alina Matei. 2023. “Package\n\"Sampling\".”",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Referencias Bibliográficas</span>"
    ]
  }
]