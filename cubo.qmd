---
title: "Muestreos balanceados y bien distribuidos"
---

```{r}
#| label: librerias_cubo

library(here)
library(readxl)
library(janitor)
library(tidyverse)
library(gt)
library(sampling)
library(gtsummary)
library(infer)
library(patchwork)
library(srvyr)
library(survey)
library(cardx)
library(downloadthis)
library(ggplot2)
library(sampling)
library(gstat)
library(sf)
library(tmap)
library(BalancedSampling)

i_am("cubo.qmd")

theme_gtsummary_language(
language = "es",
decimal.mark = ",",
big.mark = ".")
```

## Muestras Balanceadas (por el método del cubo) {#sec-cubo}

Este tipo de técnica permite diseñar muestras balanceadas en el sentido que las medias muestrales de las covariables sean (aproximadamente) iguales a las medias poblacionales de esas covariables. Esto, como mínimo, es una estrategia efectiva para evitar caer en el pequeño subconjunto de muestras aleatorias que son muy sesgadas [@tillé2011, pag. 221]. En este sentido, se recuerda que cuando realizamos diseños por azar tenemos chances (si bien bajas) de obtener muestras muy sesgadas. El muestreo balanceado evita esta situación y, la mayoría de las veces (siempre que las covariables estén empíricamente relacionadas con las variables de estudio) suele ofrecer muestras con una mejor precisión que el azar simple. Si se agregan más covariables al diseño y, nuevamente, estas se encuentran linealmente relacionadas con las variables de estudio, el estimador de la media poblacional también mejorará aún más su precisión.[^cubo-1]

Lo anterior puede considerarse un viejo *desideratum* de los diseños muestrales aunque antes no había disponible algún algoritmo de cálculo aplicable de una manera generalizable y precisa [@deville2004]. Eso es lo que precisamente logra el método del cubo. De manera alternativa, las muestras balanceadas pueden ser vistas como un tipo de calibración (@sec-calibracion) integrada en el diseño de la muestra más que a la estimación de los estimadores [@tillé2011, pag. 216].

El contexto actual de:

a)  un mayor acceso a fuentes secundarias de datos y
b)  una mayor capacidad computacional,

parece ser un contexto particularmente propicio para la aplicación y difusión de este tipo de diseños porque, justamente, se trata de un diseño demandante en cuanto a datos secundarios (en forma de información auxiliar o covariables) y demandante con respecto a recursos computacionales (el algoritmo del método del cubo). Antes de pasar a la aplicación de este diseño con la base de escuelas vamos a considerar un ejemplo trivial con variables espaciales en donde se puede simular facilmente la linealidad de la variable de estudio con respecto a otras covariables. Esto también servirá como un anticipo para cuando intentaremos incorporar explícitamente variables espaciales (coordenadas) en la muestra (@sec-bien_distribuido).[^cubo-2]

Supongamos una población como un bosque en donde tenemos alguna variable continua que nos interesa investigar. Pongamos además que, a efectos pedagógicos, nosotros sabemos la distribución de esa variable. Además, para forzar el pensamiento espacial, vamos a suponer que esa variable continua es un valor de la densidad de la vegetación para cada celda de una grilla de coordenadas y el valor de esa densidad lo visualizamos indicando un valor amarillo para sus valores más altos y azul para sus valores más bajos. A estas coordenadas se las puede clasificar como un valor en el eje "Hacia el Norte" y otro valor en el eje "Hacia el Este". Este ejemplo espacial permite construir y visualizar fácilmente la linealidad de las covariables o variables auxiliares ("Hacia el Norte" y "Hacia el Este") con la variable de estudio ("Densidad de la vegentación"). En el caso de la @fig-muestreo_cube_ejemplo se observa como a medida que vamos hacia el Norte la vegetación es algo más espesa. Lo mismo puede decirse en cuanto si vamos hacia el Este. En este sentido, el valor más alto de densidad se encuentra en la intersección de los valores más altos de los ejes anteriores o, expresado de manera alternativa, en el cuadrante superior derecho de la población. Esto quiere decir que estas variables auxiliares se encuentran empíricamente relacionadas de ***forma lineal*** con el valor de la densidad de vegetación.

En la @fig-muestreo_cube_ejemplo también se observan 2 muestras balanceadas de la población descrita en el párrafo anterior. Cada una de 4 casos cada una representadas por los cuadrados blancos. La de la izquierda se encuentra balanceada solamente por el eje "Hacia el Este" y, acorde con esto, los casos seleccionados se esparcen de Este al Oeste. La muestra de la derecha, en cambio, se encuentra balanceada por ambos ejes por lo que la distribución de los casos seleccionados no sólo varían de Esta a Oeste sino que también lo hacen de Norte a Sur. En este sentido específico, se puede afirmar que la segunda muestra es más balanceada que la primera y, de manera intuitiva, se puede afirmar que aquella es más representativa que esta.

```{r}
#| label: fig-muestreo_cube_ejemplo
#| echo: FALSE 
#| out-width: "100%"
#| fig-cap: "Muestra balanceada 'Hacia el Este' (E) y 'Hacia el Este y el Norte' (E y N)"

# Este ejemplo se realiza con la función "samplecube" de la librería sampling

# Define residual variogram for simulation
vgmodel = vgm(model = "Exp", 
               psill = 10, 
               range = 4, 
               nugget = 0)

# Define discretisation grid

x = 1:20 - 0.5
y = x
grid = expand.grid(x, y)
names(grid) = c("x1", "x2")
distx = outer(grid$x1, grid$x1, FUN = "-")
disty = outer(grid$x2, grid$x2, FUN = "-")
dist = sqrt(distx^2 + disty^2)

# Compute matrix with covariances
C = variogramLine(vgmodel, dist_vector = dist, covariance = TRUE)

# Now simulate values for grid by Cholesky decomposition
Upper = chol(C)

set.seed(31415)
G = rnorm(n = nrow(grid), 0, 1) #simulate random numbers from standard normal distribution

# Trend coefficient in x-direction
b1 = 2
b2 = 1
grid$z = crossprod(Upper, G) + b1 * grid$x1 + b2 * grid$x2

# Compute population size
N = nrow(grid)

# Set sample size
n = 4

# Define matrix with covariate for balancing; 
# First column of matrix must be filled with ones
X = cbind(rep(1, times = N), grid$x1)

# Compute inclusion probabilities; 
# Use equal probabilities
pi = rep(n / N, times = N)

nsam = 100
mx_pop = mean(grid$x1)
set.seed(31415)
repeat {
    sample_ind = samplecube(X = X, 
                             pik = pi, 
                             comment = FALSE, 
                             method = 1)
    mysample = grid[sample_ind == 1, ]
    mx_sample = mean(mysample$x1)
    if (mx_sample == mx_pop) {
      break
      }
}

# Now select a sample balanced on Easting and Northing
X = cbind(rep(1, times = N), grid$x1, grid$x2)

mx1_pop = mean(grid$x1)
mx2_pop = mean(grid$x2)
set.seed(314)
repeat {
  sample_ind = samplecube(X = X, 
                           pik = pi, 
                           comment = FALSE, 
                           method = 1)
  mysample2 = grid[sample_ind == 1, ]
  mx1_sample = mean(mysample2$x1)
  mx2_sample = mean(mysample2$x2)
  if (mx1_sample == mx1_pop & mx2_sample == mx2_pop) {
    break
    }
}

mysamples = rbind(mysample, mysample2)
mysamples$samid = rep(c("E", "E - N"), each = 4)

ggplot(data = grid) +
  geom_tile(mapping = aes(x = x1, y = x2, fill = z)) +
  geom_tile(data = mysamples, mapping = aes(x = x1, y = x2), colour = "white", linewidth = 0.8, width = 1, height = 1, fill = NA) +
  scale_fill_viridis_c(name = "z") +
  scale_x_continuous(name = "Hacia el Este >") +
  scale_y_continuous(name = "Hacia el Norte >") +
  facet_wrap(~ samid, ncol = 2, nrow = 1) +
  coord_fixed()
```

## Muestras Balanceadas sobre base de establecimientos {#sec-cubo-establecimientos}

Ahora pasaremos a aplicar este diseño a la base de escuelas que venimos trabajando. Esta vez trabajaremos con otras variables de esta base porque, precisamente, este diseño permite la introducción de una mayor cantidad de variables como información secundaria. Como en muchas otras técnicas, tener más variables no es garantía de un mejor resultado ya que la introducción de algunas variables, especialmente si no están linealmente relacionadas con las variables de estudio, puede ser contraproducente [@tillé2011, pag. 222]. Ese es precisamente una de la utilidades del ejemplo anterior ya que en el era fácil construir y visualizar la linealidad de la relación entre las covariables y la variable de estudio. Por esta razón, en este proceso de selección es importante recordar cual/es van a ser las variables de estudio para luego examinar cuales de las variables disponibles como información secundaria es conveniente utilizar como covariables. En este caso, nos focalizaremos en diferentes tipos de objetivos para demostrar la flexibilidad de la técnica. En primer lugar nos interesará tener una muestra de los establecimientos desde la base de los establecimientos (@sec-cubo_colegios) y luego una muestra de los estudiantes desde esa misma base (@sec-cubo_estudiantes).

Las lista de covariables que serán incluidas serán las siguientes:

-   Matrícula

-   Secciones

-   Región

-   Ámbito

La lista anterior funciona a modo de ejemplo aunque tiene la virtud de trabajar con información secundaria casi completa ya que se trata de variables con muy baja tasa de no respuesta. En efecto, aquí usaremos estas covariables tanto cuando nos interese averiguar características de los establecimientos como de los estudiantes pero un análisis más real implicaría usar un conjunto diferente para cada muestra porque al ser diferentes las variables de estudio también podrían/deberían ser las covariables seleccionadas.

Dicho lo anterior parece pertinente el siguiente comentario. Cuando algunos establecimientos no tienen datos en algunas de las covariables utilizadas estos no forman parte de la muestra. Esto recuerda algo que se había comentado cuando se vio el muestreo por azar simple (@sec-azar_simple). El muestreo por azar simple sólo exige una lista (y/o algún dato que luego permita su contacto empírico) de los miembros de la población. El método del cubo exige, además, el acceso a otras variables de la población en cuestión en forma de información auxiliar. Si existen casos que no tienen esa información, estos no podrán ingresar a la muestra. Esto tiene diferentes tipos de consecuencias.

La primera consecuencia es que el investigador se puede enfrentar a la disyuntiva sobre si se prefiere usar covariables completas (en el sentido que no tienen casos faltantes) pero con una menor relación con la/s variable/s de estudio o covariables incompletas pero más fuertementes relacionadas con estas últimas. Por ejemplo, las variables "sondeo_primero" y "sondeo_segundo" podrían ser opciones como covariables (siempre igual dependiendo de que se quiera investigar) pero tienen una alta tasa de no respuesta (+ de 550 casos). Para peor, al menos desde el punto de vista de la población de los establecimientos, estas no respuestas se concentran en establecimientos con una matrícula de menos de 10 estudiantes. Esto generaría un sesgo muestral porque los casos que integran la muestra (p.e. Ámbito Urbano) son diferentes a los que no integran (p.e. Ámbitos Rurales). En otras palabras, la no respuesta no es aleatoria por lo que los van a quedar dentro de la muestra serán, por diseño, diferentes a los que quedaran fuera de la misma.[^cubo-3]

### Muestra Balanceada - Población Establecimientos {#sec-cubo_colegios}

En esta primera aplicación del muestreo del cubo con la base de establecimientos vamos a tener como objetivo tener una muestra de la población de establecimientos y no, por ejemplo, de los estudiantes. En este caso las probabilidades de inclusión son iguales para establecimiento. De todos modos la técnica, en otro indicador de su flexibilidad, permite realizar muestras con diferentes probabilidades de inclusión.

```{r}
#| label:  muestra_cubo_colegios

base = read_rds(here("Outputs", "base.rds"))

# Es importante que se puedan convertir a numeros las categorias de las variables. Esto implica en algunos casos que primero se conviertan a factores.

tb = base |>
select(matricula, secciones, sondeo_primero, sondeo_segundo, ambito, region, clave) |>
drop_na(matricula, secciones, ambito, region) |>
rowid_to_column() |>
mutate(ambito_n = case_when(
      ambito == "Urbano" ~ 1,
      ambito == "Rural Disperso" ~ 2,
      ambito == "Rural Agrupado" ~ 3))

N = nrow(tb)
n = 300
X = cbind(rep(1, times = N), 
          as.numeric(tb$matricula),
          as.numeric(tb$secciones),
          as.numeric(tb$region),
          as.numeric(tb$ambito))
pi_colegio = rep(n / N, times = N)


tb = bind_cols(tb, as.data.frame(pi_colegio)) |>
relocate("pi_colegio", .after = "rowid")

set.seed(314)

muestra_balanceada_colegios = cube(prob = pi_colegio, 
                                   x = X,
                                   eps = 1e-12)

muestra_cubo_colegios = tb[muestra_balanceada_colegios, ] |>
mutate(pw = N/n,
       fpc = sqrt((N-n)/(N-1)))

muestra_cubo_colegios_sv = muestra_cubo_colegios |>
as_survey_design(id = 1,
                 weights = pw,
                 fpc = fpc)

```

```{r}
#| label: muestra_cubo_estratificada
#| eval: false
# Lo ordeno porque esto es necesario para la estratificación

tb = tb |>
 arrange(ambito)
 
 N = nrow(tb)
 n = 300
 X2 = cbind(rep(1, times = N), 
           tb$matricula, 
           tb$secciones)
 
 pi_colegio = rep(n / N, times = N)
 
 strata = as.integer(tb$ambito_n)
 
 muestra_bal_estratificada = 
              cubestratified(prob = pi_colegio, 
                             x = X2,
                             integerStrata = strata,
                             eps = 1e-4)
```

```{r}
#| label: muestra_cubo_lib_sampling
#| eval: false
#| echo: false
 
#Uso la librería sampling

muestra_balanceada_colegios_sampling = samplecube(pik = pi_colegio,
                                            X = X) |>
 as.data.frame() |>
 rename(muestra = 1)

muestra_cubo_colegios_sampling = bind_cols(tb, muestra_balanceada_colegios_sampling) |>
 filter(muestra == 1) |> # Porque la libreria sampling 
 mutate(pw = N/n,
        fpc = sqrt((N-n)/(N-1)))

 muestra_cubo_colegios_sv_sampling = muestra_cubo_colegios_sampling |>
 as_survey_design(id = 1,
                  weights = pw,
                  fpc = fpc)
```

En la @tbl-cubo_colegios se puede observar los resultados de la muestra balanceada para colegios. En esta los resultados se comparan con los resultados anteriores de la muestra de azar simple y los respectivos totales poblacionales. Como se aclaró anteriormente en estas tablas no se van a incluir ni el error estándar ni los intervalos de confianza dada lo incómodo de su cálculo y posterior visualización en tablas. De todos modos, se alcanza a visualizar que en muchas de las variables analizadas existe una pequeña mejora con la excepción de algunas categorías de la variable Región.[^cubo-4]

```{r}
#| label: tbl-cubo_colegios
#| tbl-cap: Estimaciones con muestra balanceada para colegios

tbl_cubo_colegios = muestra_cubo_colegios_sv |>
tbl_svysummary(
include = c(matricula, secciones, sondeo_primero, sondeo_segundo, region, ambito),
statistic = list(all_continuous() ~ "{mean}",
                all_categorical() ~ "{p}% (n={n_unweighted})"),
digits = list(all_continuous() ~ c(1),
              all_categorical() ~ c(1,0))) |>
  # add_ci()  |>
modify_footnote(all_stat_cols() ~ "Media (DE); % (n sin ponderar)")

tbl_cubo_colegios  


# tbl_cubo_colegios_sampling = muestra_cubo_colegios_sv_sampling |>
# tbl_svysummary(
# include = c(matricula, sondeo_primero, sondeo_segundo, region, ambito),
# digits = list(deff = label_style_number(digits = 3),
#               sd = label_style_number(digits = 3)),
# statistic = list(all_continuous() ~ "{mean} ({sd})",
#                 all_categorical() ~ "{p}% (n={n_unweighted})")) |>
# add_ci()  |>
# modify_footnote(all_stat_cols() ~ "Media (DE); % (n sin ponderar)")
# 
# tbl_cubo_colegios_sampling  
  
muestra_azar_simple_sv = read_rds(here("Outputs", "muestra_azar_simple_sv.rds"))

tbl_azar_simple = muestra_azar_simple_sv |>
tbl_svysummary(
include = c(matricula, secciones, sondeo_primero, sondeo_segundo, region, ambito),
statistic = list(all_continuous() ~ "{mean}",
                all_categorical() ~ "{p}% (n={n_unweighted})"),
digits = list(all_continuous() ~ c(1),
              all_categorical() ~ c(1,0))) |>
modify_footnote(all_stat_cols() ~ "Media (DE); % (n sin ponderar)")

# tbl_azar_simple = read_rds(here("Outputs", "tbl_azar_simple.rds"))
 tbl_pob_param = read_rds(here("Outputs", "tbl_pob_param.rds"))
# tbl_summary(include = c(region, matricula, secciones, ambito),
#             statistic = list(
#       all_continuous() ~ "{mean} ({p25}, {p75})",
#       all_categorical() ~ "{p}% ({n})"))
# 
# 
# 
tbl_merge(
   tbls = list(tbl_cubo_colegios, tbl_azar_simple, tbl_pob_param),
   tab_spanner = c("**Cubo Colegios**", "**Azar Simple**", "**Pob. Colegios**")
 )

```

### Muestra Balanceada - Población Estudiantes {#sec-cubo_estudiantes}

En esta pequeña sección vamos a observar la flexibilidad de la técnica del cubo obteniendo una muestra en donde las probabilidades de inclusión son diferentes. En este caso particular se aplicará el criterio que esas probabilidades sean proporcionales al tamaño de la matrícula. Esto tiene consecuencias similares a lo visto en la (@sec-pps) en donde, por diseño, los establecimientos con mayor matrícula tienen una mayor chance de ser incluidos en la muestra. La diferencia con el muestreo PPS es quel muestreo balanceado permite, además, un conjunto de otras covariables que, nuevamente, reducen las chances que la muestra finalmente seleccionada sean una de las pocas sesgadas. A continuación, en la @tbl-cubos_matricula_comparacion puede observarse como

```{r}
#| label: muestra_cubo_matricula

# Acá la probabilidad de inclusión es por el tamaño de la matrícula

pi_matricula = inclusionprobabilities(tb$matricula, n)

tb = bind_cols(tb, as.data.frame(pi_matricula)) |>
relocate("pi_matricula", .after = "rowid")

N = nrow(tb)
n = 300
X = cbind(rep(1, times = N), 
          as.numeric(tb$matricula),
          as.numeric(tb$secciones),
          as.numeric(tb$region),
          as.numeric(tb$ambito))
  
set.seed(314)

muestra_balanceada_matricula = cube(prob = pi_matricula, 
                                    x = X)

muestra_cubo_matricula = tb[muestra_balanceada_matricula, ] |>
mutate(fpc = sqrt((N-n)/(N-1)),
       pw = N / n)

muestra_cubo_matricula_sv = muestra_cubo_matricula |>
as_survey_design(id = 1,
                 weights = pw,
                # strata = ambito,
                 fpc = fpc,
                 pps = "brewer")

```

```{r}
#| label: tbl-cubo_matricula
#| tbl-cap: Estimaciones con muestra balanceada para población de estudiantes

tbl_cubo_matricula = muestra_cubo_matricula_sv |>
tbl_svysummary(
include = c(matricula, secciones, sondeo_primero, sondeo_segundo, region, ambito),
statistic = list(all_continuous() ~ "{mean}",
                all_categorical() ~ "{p}% (n={n_unweighted})"),
digits = list(all_continuous() ~ c(1),
              all_categorical() ~ c(1,0)),
missing = "no") |>
modify_footnote(all_stat_cols() ~ "Media (DE); % (n sin ponderar)")

```

```{r}
#| label: tbl-cubos_matricula_comparacion
#| tbl-cap: Comparación muestra balanceada por la matrícula y muestra PPS sin ponderar y poblacion de establecimientos ponderada por matrícula

tbl_pob_pond_matricula = tb |>
as_survey_design(ids = rowid,
                 weights = matricula) |>
tbl_svysummary(include = c(matricula, secciones,sondeo_primero, sondeo_segundo, region, ambito),
            statistic = list(all_continuous() ~ "{mean}",
                             all_categorical() ~ "{p}% (n={n_unweighted})"),
digits = list(all_continuous() ~ c(1),
              all_categorical() ~ c(1,0)),
missing = "no")

muestra_pps_sin_ponderar_sv = read_rds(here("Outputs", "muestra_pps_sin_ponderar_sv.rds"))

tbl_pps_sin_ponderar = muestra_pps_sin_ponderar_sv |>
tbl_svysummary(
include = c(matricula, secciones, sondeo_primero, sondeo_segundo, region, ambito),
statistic = list(all_continuous() ~ "{mean}",
                all_categorical() ~ "{p}% (n={n_unweighted})"),
digits = list(all_continuous() ~ c(1),
              all_categorical() ~ c(1,0)),
missing = "no")
 
tbl_merge(
   tbls = list(tbl_cubo_matricula, tbl_pps_sin_ponderar, tbl_pob_pond_matricula),
   tab_spanner = c("**Cubo Matrícula**", "**PPS sin ponderar**", "**Pob. matricula**")
 ) |>
modify_header((all_stat_cols() ~ "")) |>
modify_footnote(everything() ~ NA)

```

## Muestreos bien distribuidos {#sec-bien_distribuido}

Como se dijo en la @sec-cubo en los muestreos balanceados por el método del cubo el esfuerzo está en que los valores de la tendencia central de los estimadores de determinadas variables de la muestra se acerquen a los valores de las covariables existentes como información secundaria, esto es, a los parámetros conocidos de la población. En el muestreo bien extendido (*well spread*) es objetivo es similar pero con una restricción adicional que implica que la distribución de la/s covariable/s de la muestra se acerque a la distribución de la/s covariable/s en la población. El precio de esta mejora es que se debe conocer la distribución de esas variables en la población algo que nunca habían requerido los diseños anteriores. En el caso particular de la distribución espacial el diseño exige la introducción de las coordenadas de cada miembro de la población y no solo el promedio poblacional de ellas.

En este contexto cobra importancia el ejemplo inicial de la @sec-cubo en donde se usaron covariables espaciales. Allí, de manera intuitiva, se asoció que una muestra bien distribuida es una muestra balanceada. Esta afirmación, útil como un primera aproximación, es verdadera pero su inversa no. En otras palabras, toda muestra balanceada no es bien distribuida, pero toda muestra bien distribuida sí es una muestra balanceada.

A continuación trabajaremos con los misma muestra balanceada de colegios de la sección anterior pero le agregaremos la condición de que esa muestra *también* sea bien distribuida en los valores de las coordenadas geográficas. Para eso primero agregaremos las coordenadas a la base de los establecimientos.

```{r}
#| label: coordenadas

coordenadas = read_xlsx(here("Inputs", "Nómina de establecimientos 20241020.xlsx")) |>
select(latitud, longitud, clave)
```

```{r}
#| label: add_coordenadas

tb = tb |>
left_join(coordenadas, by = "clave") |>
filter(!is.na(latitud)) |>
filter(!is.na(longitud))

```

Agregadas las coordenadas ahora se puede aplicar la técnica del cubo con el adicional que el balanceo no sólo se realice por los valores de tendencia central de la sección anterior, sino también con los valores de dispersión de las coordenadas de los establecimientos.

En cierto sentido, la inclusión de las variables "Ámbito" y "Región" en el diseño balanceado (@sec-cubo_colegios) ya mejoraban la distribución geográfica o espacial de la muestra (con respecto a una muestra de azar simple) pero lo hacían focalizándonse en sus valores de tendencia central. Los valores de las coordenadas permiten una información de un grano más fino sobre la distribución espacial de la muestra. En efecto, al usarse esta última información en un diseño bien distribuido se aprecia una leve mejora en los valores que tienen una fuerte influencia espacial (p.e "Ambito" y "Región").

```{r}
#| label: muestreo_bien_distribuidos

N = nrow(tb)
n = 300
X = cbind(rep(1, times = N), 
          as.numeric(tb$matricula),
          as.numeric(tb$secciones),
        #  as.numeric(tb$matri_seccion),
         # as.numeric(tb$indice_de_vulnerabilidad), 
          as.numeric(tb$region),
          as.numeric(tb$ambito))
        #  as.numeric(tb$jornada))
pi_colegio = rep(n / N, times = N)

xy = cbind(tb$latitud, tb$longitud)

set.seed(314)

muestra_bien_distribuida = lcube(Xbal = X, 
                            Xspread = xy , 
                            prob = pi_colegio)

muestra_bien_distribuida = tb[muestra_bien_distribuida,] |>
mutate(pw = N/n,
       fpc = sqrt((N-n)/(N-1)))

muestra_bien_distribuida_sv = muestra_bien_distribuida |>
as_survey_design(id = 1,
                 weights = pw,
                 fpc = fpc)

write_rds(muestra_bien_distribuida_sv,
          here("Outputs", "muestra_bien_distribuida_sv.rds"))
```

```{r}
#| label: tbl-bien_distribuida
#| tbl-fig: sdvdsvv
 
tbl_bien_distribuida = muestra_bien_distribuida_sv |>
tbl_svysummary(
include = c(matricula, secciones, sondeo_primero, sondeo_segundo, region, ambito),
digits = list(deff = label_style_number(digits = 3),
              sd = label_style_number(digits = 3)),
statistic = list(all_continuous() ~ "{mean} ({mean.std.error})",
                all_categorical() ~ "{p}% (n={n_unweighted})")) |>
add_ci()  |>
modify_footnote(all_stat_cols() ~ "Media (DE); % (n sin ponderar)")

write_rds(tbl_bien_distribuida,
          here("Outputs", "tbl_bien_distribuida.rds"))

tbl_merge(
   tbls = list(tbl_bien_distribuida, tbl_cubo_colegios, tbl_pob_param),
   tab_spanner = c("**Bien distribuida**", "**Cubo colegios**", "**Pob. Colegios**")
 )  


```

En ciencias sociales, la mejora de la distribución espacial de una muestra no es un mejora cualquiera. Es una mejora muy interesante porque también ayuda a controlar, una serie de otras variables que se pueden presumir asociadas al espacio pero no fácilmente accesibles de forma empírica o, por lo menos, no accesible en términos de parámetros poblacionales para el momento del diseño de una muestra. Expresado en jerga metodológica, este tipo de mejoras ayudan a controlar una serie de variables extrañas haciendo que dejen de ser variables perturbadoras [@kish1987].

De todos modos, en este caso particular es razonable suponer que la ubicación de los establecimientos guarda relación con la ubicación de los estudiantes y, más en general, con la distribución de las personas.

```{r}
#| label: fig-mapa_bien_distribuida
#| cache: true

tb = tb |>
st_as_sf(coords = c("longitud", "latitud"),
         dim = "XY",
         sf_column_name = "geom_escuela",
         crs = 4326)

muestra_bien_distribuida = muestra_bien_distribuida |>
st_as_sf(coords = c("longitud", "latitud"),
         dim = "XY",
         sf_column_name = "geom_escuela",
         crs = 4326)

tmap_mode("view")

fig_bien_distribuida = tm_basemap(server = "CartoDB.Positron",
           alpha = 0.5) +
tm_shape(tb,
         name = "Población") +
tm_dots(fill_alpha = 0.20,
        fill = "black") +
tm_shape(muestra_bien_distribuida,
         name = "Muestra bien distribuida") +
tm_dots(fill_alpha = 0.9,
        fill = "blue")

fig_bien_distribuida 

```

[^cubo-1]: Más adelante veremos que indagar sobre la precisión de la estimación es posible pero difícil en las muestras realizadas con el método del cubo. Por esta razón, si bien es posible comparar la precisión de estas muestras contra, por ejemplo, el muestreo por azar simple, acá se tomará como un supuesto y se remite al lector a fuentes en donde se prueba lo anterior [@brus2022, cap. 9][@schneider2024]. El principal problema es que, por ahora, las librerías de análisis de datos de encuestas (p.e. survey) todavía no tienen el instrumental adecuado para especificar este tipo de diseños y, por lo tanto, para calcular la precisión de sus estimaciones.

[^cubo-2]: El ejemplo y el respectivo código fue adaptado del libro "Spatial sampling with R" [@brus2022].

[^cubo-3]: En este sentido, más que nada por razones pedagógicas, aquí se han elegido como covariables, un conjunto de variables con poco margen de no respuesta. Esto se debe a que, si se hubieran escogido covariables con una alta tasa de no respuesta, se presenta el problema de contra que conjunto de datos testear las bondades de la técnica del cubo. Esto es así dado que si los resultados de la técnica del cubo se comparan contra los totales poblacionales de los colegios (@tbl-parametros_base) es esperable que los resultados vayan a ser diferentes porque, estrictamente, la técnica del cubo se realiza sólo sobre los establecimientos que tienen la información auxiliar pertinente. Lo mismo, *mutatis mutandi*, si se compara con la respectiva de azar simple de toda la población de colegios (@tbl-azar_simple).

[^cubo-4]: Es posible que parte del los mayores errores en algunas categorías de la variable Región se deban a que la falta de datos en algunas de las covariables elegidas sea desigual según Región. De todos modos, la cantidad de casos (establecimientos) que no tenían las covariables completas era 9.
