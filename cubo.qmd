---
title: "Muestreos Especiales"
---

```{r}

library(here)
library(readxl)
library(janitor)
library(tidyverse)
library(gt)
library(sampling)
library(gtsummary)
library(infer)
library(patchwork)
library(srvyr)
library(survey)
library(cardx)
library(downloadthis)
library(ggplot2)
library(sampling)
library(BalancedSampling)
library(gstat)
library(sf)
library(tmap)

i_am("cubo.qmd")

theme_gtsummary_language(
language = "es",
decimal.mark = ",",
big.mark = ".")
```

## Muestras complejas

Las muestras complejas son una familia de muestras que tienen en común la combinación de diseños muestrales más simples como los vistos anteriormente. En general, esta combinación se produce en pasos o etapas por lo que también se los suele denominar "muestreos polietápicos". Desde un punto de vista más práctico esta combinación suele realizar para aprovechar la posible sinergia entre los pro y contras de cada tipo de muestreo sea tanto para producir muestras más baratas (lo que suele redundar en más viabilidad) o más precisas. Desde un punto de vista más teórico las muestras complejas tienen el problema que es más difícil luego trabajar con ellas dado que es más difícil calcular los márgenes de error.

Esto último no es un problema menor. En efecto, en la historia de las técnicas de muestreo los muestristas de la segunda mitad del siglo XX ya sabían que "mezclar" diferentes tipos de muestreo clásicos en diferentes etapas tenía beneficios aunque fuera relativamente difícil estimar la magnitud específica de ese beneficio en cada caso. Esto produjo un período de la historia en donde los "muestristas" diseñaban y ejecutaban muestras complejas pero luego los analistas las trabajaban "como si" fueran alguna de las muestras simples. Esta situación creo un nicho para que surgieran conceptos como los "efectos de diseño" (*design effect o deff*) que facilitó durante décadas los análisis de los datos de este tipo de muestras.

La estrategia que se encuentra por detrás del concepto de efecto de diseño es relativamente simple de interpretar y de ahí su popularidad. Es un coeficiente que dice que tanto más chico o que tanto más grande es el error del diseño de la muestra comparada contra el error de una muestra con un diseño de azar simple. Esta simplicidad en su interpretación permitió dos fenómenos complementarios. Por un lado que cobre visibilidad algunos de los beneficios de las estrategias de los muestristas que insistían en la combinación de tipos de muestreos. Por otro lado, que los analistas de datos dejen de analizar esas muestras como si fueran muestras de azar simple y pasen a un estadio más realista en donde al cálculo anterior se lo ajusta por el factor "efecto de diseño". El ideal sería que ese factor de diseño (como así también el respectivo error del azar simple) se calcule para cada variable específica que se analiza pero esto, gracias al aumento de las potencias de las computadoras y el crecimiento de programas y librerías especializadas, sólo es factible en tiempos contemporáneos. Antes, este coeficiente lo calculaba una vez del muestrista y luego se lo pasaba a quienes iban a realizar el análisis de datos (y en general estos luego lo aplicaban/extendían a todas las variables de la muestra).

El ejemplo más típico de muestra compleja quizá sea el que primero conglomera y luego realiza otro (o otros) pasos como estratificar o algún muestreo sistemático.

FALTA

Construcción de ponderadores

replicación de ponderadores

Muestras Complejas

Calibración

<https://tidyclust.tidymodels.org/>

## Muestreo por Clusters

El muestreo por cluster es otra manera de aplicar el azar para diseñar muestras. A diferencia del muestreo estratificado en el muestreo por cluster el investigador considera a los cluster como "racimos" de casos que, de alguna manera, se encuentran cercanos geográficamente pero no necesariamente socialmente o, más en general, no son homogéneos en las variables de estudio. En efecto, la ventaja de este tipo de muestreo es que abarata costos en la ejecución de muestras espacialmente extensas. El precio que se paga es un aumento en el error standard pero, justamente, el quid de la cuestión es que en algunas situaciones el investigador necesita o prefiere la reducción de costos por lo que el precio lo paga con gusto.

que muchas veces o bien es suplantado con una mayor cantidad de casos o bien es mitigado en una etapa posterior del muestreo.

## Muestreo del Cubo {#sec-cubo}

Este tipo de técnica permite diseñar muestras balanceadas en el sentido que las medias muestrales de las covariables son (aproximadamente) iguales a las medias poblacionales de esas covariables. Esto, como mínimo, es una estrategia efectiva para evitar caer en el pequeño subconjunto de muestras aleatorias que son muy sesgadas [@tillé2011, pag. 221]. Cuando realizamos diseños sólo por azar tenemos chances (si bien bajas) de obtener muestras muy sesgadas. El muestreo balanceado evita esta situación y, la mayoría de las veces (aunque depende del tipo e intensidad de las covariables) suele ofrecer muestras con una mejor precisión que el azar simple.

En estos casos, si esas covariables seleccionadas están linealmente relacionadas con las variables de estudio, se obtiene un estimador más preciso de la media poblacional o el total de las variables de estudio. Si se agregan más covariables al diseño y, nuevamente, estas se encuentran linealmente relacionadas con las variables de estudio, el estimador de la media poblacional será también más preciso.

Lo anterior es un viejo un viejo *desideratum* de los diseños muestrales pero antes no había disponible algún algoritmo de cálculo que permitiera lo anterior de una manera generalizable y precisa [@deville2004]. En efecto, las muestras balanceadas pueden ser vistas como un tipo de calibración que es directamente integrada en el diseño de la muestra [@tillé2011, pag. 216].

El contexto actual de:

a)  un mayor acceso a fuentes secundarias de datos y

b\) una mayor capacidad computacional,

parece ser un contexto particularmente propicio para la aplicación de este tipo de diseños porque, justamente, se trata de un diseño demandante en cuanto a datos secundarios y demandante con respecto a recursos computacionales. Antes de pasar a la aplicación con la base de escuelas vamos a considerar un ejemplo trivial con variables espaciales en donde es posible simular la linealidad de la variable de estudio con respecto a otras covariables. Esto también servirá como un anticipo para cuando intentaremos incorporar explícitamente variables espaciales (coordenadas) en la muestra.[^cubo-1]

Supongamos una población como un bosque en donde tenemos alguna variable continua que nos interesa investigar. Pongamos además que, a efectos pedagógicos, nosotros sabemos la distribución de esa variable. Además, para forzar el pensamiento espacial, vamos a suponer que esa variable continua es un valor de la densidad de la vegetación para cada celda de una grilla de coordenadas y el valor de esa densidad lo visualizamos indicando un valor amarillo para sus valores más altos y azul para sus valores más bajos. Estas coordenadas se las puede clasificar como un valor en el eje "Hacia el Norte" y otro valor en el eje "Hacia el Este". Estas variables espaciales van a ser las **variables auxiliares** que se utilizan como covariables y que necesita el diseño del cubo para funcionar. En el caso de la @fig-muestreo_cube_ejemplo se observa como a medida que vamos hacia el Norte la vegetación es algo más espesa. Lo mismo puede decirse en cuanto si vamos hacia el Este. En este sentido, el valor más alto de densidad se encuentra en la intersección de los valores más altos de los ejes anteriores o, expresado de manera alternativa, en el cuadrante superior derecho de la población. Esto quiere decir que estas variables auxiliares se encuentran empíricamente relacionadas de ***forma lineal*** con el valor de la densidad de vegetación. Y por eso último, tener datos de variables auxiliares es útil para este diseño.

En la @fig-muestreo_cube_ejemplo también se observan 2 muestras balanceadas de la población descrita en el párrafo anterior. Cada una de 4 casos cada una. La de la izquierda se encuentra balanceada solamente por el eje "Hacia el Este" y, acorde con esto, los casos seleccionados se esparcen de Este al Oeste. La muestra de la derecha, en cambio, se encuentra balanceada por ambos ejes por lo que la distribución de los casos seleccionados no sólo varían de Esta a Oeste sino que también lo hacen de Norte a Sur. En este sentido específico, se puede afirmar que la segunda muestra es más balanceada que la primera y, de manera intuitiva, se puede afirmar que aquella es más representativa que esta.

```{r}
#| label: fig-muestreo_cube_ejemplo
#| echo: FALSE 
#| out-width: "100%"
#| fig-cap: "Muestra balanceada 'Hacia el Este' (E) y 'Hacia el Este y el Norte' (E y N)"

library(gstat)
library(sampling)
# Define residual variogram for simulation
vgmodel <- vgm(model = "Exp", 
               psill = 10, 
               range = 4, 
               nugget = 0)

# Define discretisation grid

x = 1:20 - 0.5
y = x
grid = expand.grid(x, y)
names(grid) = c("x1", "x2")
distx = outer(grid$x1, grid$x1, FUN = "-")
disty = outer(grid$x2, grid$x2, FUN = "-")
dist = sqrt(distx^2 + disty^2)

# Compute matrix with covariances
C <- variogramLine(vgmodel, dist_vector = dist, covariance = TRUE)

# Now simulate values for grid by Cholesky decomposition
Upper <- chol(C)

set.seed(31415)
G <- rnorm(n = nrow(grid), 0, 1) #simulate random numbers from standard normal distribution

# Trend coefficient in x-direction
b1 <- 2
b2 <- 1
grid$z <- crossprod(Upper, G) + b1 * grid$x1 + b2 * grid$x2

# Compute population size
N <- nrow(grid)

# Set sample size
n <- 4

# Define matrix with covariate for balancing; 
# First column of matrix must be filled with ones
X <- cbind(rep(1, times = N), grid$x1)

# Compute inclusion probabilities; 
# Use equal probabilities
pi <- rep(n / N, times = N)

nsam <- 100
mx_pop <- mean(grid$x1)
set.seed(31415)
repeat {
    sample_ind <- samplecube(X = X, 
                             pik = pi, 
                             comment = FALSE, 
                             method = 1)
    mysample <- grid[sample_ind == 1, ]
    mx_sample <- mean(mysample$x1)
    if (mx_sample == mx_pop) {
      break
      }
}

# Now select a sample balanced on Easting and Northing
X <- cbind(rep(1, times = N), grid$x1, grid$x2)

mx1_pop <- mean(grid$x1)
mx2_pop <- mean(grid$x2)
set.seed(314)
repeat {
  sample_ind <- samplecube(X = X, 
                           pik = pi, 
                           comment = FALSE, 
                           method = 1)
  mysample2 <- grid[sample_ind == 1, ]
  mx1_sample <- mean(mysample2$x1)
  mx2_sample <- mean(mysample2$x2)
  if (mx1_sample == mx1_pop & mx2_sample == mx2_pop) {
    break
    }
}

mysamples <- rbind(mysample, mysample2)
mysamples$samid <- rep(c("E", "E - N"), each = 4)

ggplot(data = grid) +
  geom_tile(mapping = aes(x = x1, y = x2, fill = z)) +
  geom_tile(data = mysamples, mapping = aes(x = x1, y = x2), colour = "white", linewidth = 0.8, width = 1, height = 1, fill = NA) +
  scale_fill_viridis_c(name = "z") +
  scale_x_continuous(name = "Hacia el Este >") +
  scale_y_continuous(name = "Hacia el Norte >") +
  facet_wrap(~ samid, ncol = 2, nrow = 1) +
  coord_fixed()
```

## Muestreo Cubo sobre base de establecimientos

Ahora pasaremos a aplicar este diseño a la base de escuelas que venimos trabajando. Esta vez trabajaremos con otras variables porque, precisamente, este diseño permite la introducción de una mayor cantidad de variables como información secundaria. Como en muchas otras técnicas, tener más variables no es garantía de un mejor resultado ya que la introducción de algunas variables puede ser contraproducente [@tillé2011, pag. 222]. Ese es precisamente una de la utilidades del ejemplo anterior ya que en el era fácil construir y visualizar la linealidad de la relación entre las covariables y la variable de estudio. Por esta razón, en este proceso de selección es importante recordar cual/es son los parámetros a estimar para luego, examinar cuales de las variables disponibles como información secundaria es conveniente utilizar. En este caso, nos focalizaremos en diferentes tipos de objetivos para demostrar la flexibilidad de la técnica. En primer lugar nos interesará tener una muestra de colegios y luego una de los estudiantes. Finalmente complementaremos ambos objetivos anteriores con la idea muestras bien distribuidas (*well spread*).

Las lista de covariables que serán incluidas serán las siguientes:

-   Matrícula

-   Secciones

-   Región

-   Ámbito

La lista anterior funciona a modo de ejemplo aunque tiene la virtud de trabajar con información secundaria casi completa ya que se trata de variables con muy baja tasa de no respuesta. En efecto, aquí usaremos las mismas tanto cuando nos interese averiguar características de los establecimientos como de los estudiantes pero un análisis más real implicaría usar un conjunto diferente para cada muestra porque las variables de estudio serán diferente dependiendo de la población que se quiera analizar.

### Muestreo Cubo - Población Establecimientos {#sec-cubo_colegios}

En esta primera aplicación del muestreo del cubo con la base de establecimientos vamos a tener como objetivo tener una muestra de la población de establecimientos y no, por ejemplo, de estudiantes. En este caso las probabilidades de inclusión son iguales para establecimiento. De todos modos, la técnica permite realizar muestras con diferentes probabilidades de inclusión.

Dicho lo anterior parece pertinente el siguiente comentario. Cuando algunos establecimientos no tienen datos en algunas de las covariables utilizadas estos no forman parte de la muestra. Si bien son pocos, esto ejemplifica algo que se había comentado cuando se vio el muestreo por azar simple. El muestreo por azar simple sólo exige una lista (y/o algún dato que permita su contacto empírico) de los miembros de la población. El método del cubo exige, además, el acceso a otras variables de la población en cuestión. Si existen casos que no tienen esa información, estos no pueden ingresar a la muestra. Esto tiene consecuencias tanto en el momento de la utilización práctica de la técnica como consecuencias pedagógicas. Aquí sólo señalaremos 2.

Como ejemplo de una consecuencia en la utilización práctica invita a pensar si se prefiere usar covariables completas (en el sentido que no tienen casos faltantes) pero con una mayor lejanía a la/s variable/s de estudio o covariables incompletas pero más fuertementes relacionadas con estas últimas.[^cubo-2]

Ejemplo de una consecuencia pedagógica es lo siguiente. Dependiendo de que aspecto de la técnica del cubo se desea visualizar y de que opción del párrafo anterior se haya preferido, será más idóneo la elección de una determinada población o muestra contra lo cual comparar sus resultados. En este sentido, si los resultados de la técnica del cubo se comparan contra los totales poblacionales de los colegios (@tbl-parametros_base) es esperable que los resultados vayan a ser diferentes porque, estrictamente, la técnica del cubo se realiza sólo sobre los establecimientos que tienen la información pertinente. Lo mismo, *mutatis mutandi*, si se compara con la respectiva de azar simple de toda la población de colegios (@tbl-azar_simple). Una opción, al menos para visibilizar las ventajas de esta técnica, es comparar con la población o una muestra de azar simple de la subpoblación de los establecimientos que tienen la información secundaria. Esto cobra importancia si, por ejemplo, se prefirió utilizar una lista de covariables incompletas.

```{r}
#| label:  muestra_cubo_colegios

levels_region = c("01", "02", "03", "04", "05", "06", "07",
                  "08", "09", "10", "11", "12", "13", "14",
                  "15", "16", "17", "18", "19", "20", "21",
                  "22", "23", "24", "25")

# Saco matrícula que es la que voy a estimar

base = read_xlsx(here("Inputs", "base_escuelas_primaria.xlsx")) |>
clean_names() |>
mutate(ambito = as_factor(ambito),
       region = as_factor(region),
       region = fct_relevel(region, levels_region))

tb = base |>
select(matricula, secciones, sondeo_primero, sondeo_segundo, matri_seccion, indice_de_vulnerabilidad, indice_presencialidad_total, jornada, ambito, region, clave) |>
#filter(matricula >= 1) |>
#filter(sondeo_primero >= 0) |>
#filter(indice_de_vulnerabilidad >= 0) |>
rowid_to_column() |>
mutate(ambito_n = case_when(
      ambito == "Urbano" ~ 1,
      ambito == "Rural Disperso" ~ 2,
      ambito == "Rural Agrupado" ~ 3)) |>
mutate(jornada = as.factor(jornada))

#cube(prob, C, eps = 1e-12)
N = nrow(tb)
n = 300
X = cbind(rep(1, times = N), 
          as.numeric(tb$matricula),
          as.numeric(tb$secciones),
        #  as.numeric(tb$matri_seccion),
         # as.numeric(tb$indice_de_vulnerabilidad), 
          as.numeric(tb$region),
          as.numeric(tb$ambito))
        #  as.numeric(tb$jornada))
pi_colegio = rep(n / N, times = N)


tb = bind_cols(tb, as.data.frame(pi_colegio)) |>
relocate("pi_colegio", .after = "rowid")

set.seed(314)

muestra_balanceada_colegios = cube(prob = pi_colegio, 
                                   x = X)

# muestra_balanceada_colegios_sampling = samplecube(pik = pi_colegio,
#                                            X = X) |>
# as.data.frame() |>
# rename(muestra = 1)

# muestra_cubo_colegios_sampling = bind_cols(tb, muestra_balanceada_colegios_sampling) |>
# filter(muestra == 1) |> # Porque la libreria sampling 
# mutate(pw = N/n,
#        fpc = sqrt((N-n)/(N-1)))

# muestra_cubo_colegios_sv_sampling = muestra_cubo_colegios_sampling |>
# as_survey_design(id = 1,
#                  weights = pw,
#                  fpc = fpc)

muestra_cubo_colegios = tb[muestra_balanceada_colegios, ] |>
mutate(pw = N/n,
       fpc = sqrt((N-n)/(N-1)))

muestra_cubo_colegios_sv = muestra_cubo_colegios |>
as_survey_design(id = 1,
                 weights = pw,
                 fpc = fpc)

```

```{r}
#| label: muestra_cubo_estratificada
#| eval: false
# Lo ordeno porque esto es necesario para la estratificación

# tb = tb |>
# arrange(ambito)
# 
# N = nrow(tb)
# n = 300
# X2 = cbind(rep(1, times = N), 
#           tb$matri_seccion, 
#           tb$sondeo_primero, 
#           tb$indice_de_vulnerabilidad)
# pi_colegio = rep(n / N, times = N)
# 
# strata = as.integer(tb$ambito_n)
# 
# muestra_bal_estratificada = 
#              cubestratified(prob = pi_colegio, 
#                             x = X,
#                             integerStrata = strata,
#                             eps = 1e-4)
```

```{r}
#| label: tbl-cubo_colegios
#| tbl-cap: Estimaciones con muestra balanceada para colegios

tbl_cubo_colegios = muestra_cubo_colegios_sv |>
tbl_svysummary(
include = c(matricula, secciones, sondeo_primero, sondeo_segundo, region, ambito),
digits = list(deff = label_style_number(digits = 3),
              sd = label_style_number(digits = 3)),
statistic = list(all_continuous() ~ "{mean} ({sd})",
                all_categorical() ~ "{p}% (n={n_unweighted})")) |>
add_ci()  |>
modify_footnote(all_stat_cols() ~ "Media (DE); % (n sin ponderar)")

tbl_cubo_colegios  


# tbl_cubo_colegios_sampling = muestra_cubo_colegios_sv_sampling |>
# tbl_svysummary(
# include = c(matricula, sondeo_primero, sondeo_segundo, region, ambito),
# digits = list(deff = label_style_number(digits = 3),
#               sd = label_style_number(digits = 3)),
# statistic = list(all_continuous() ~ "{mean} ({sd})",
#                 all_categorical() ~ "{p}% (n={n_unweighted})")) |>
# add_ci()  |>
# modify_footnote(all_stat_cols() ~ "Media (DE); % (n sin ponderar)")
# 
# tbl_cubo_colegios_sampling  
  

 tbl_azar_simple = read_rds(here("Outputs", "tbl_azar_simple.rds"))
 tbl_pob_param = read_rds(here("Outputs", "tbl_pob_param.rds"))
# tbl_summary(include = c(region, matricula, secciones, ambito),
#             statistic = list(
#       all_continuous() ~ "{mean} ({p25}, {p75})",
#       all_categorical() ~ "{p}% ({n})"))
# 
# 
# 
tbl_merge(
   tbls = list(tbl_cubo_colegios, tbl_azar_simple, tbl_pob_param),
   tab_spanner = c("**Cubo Colegios**", "**Azar Simple**", "**Pob. Colegios**")
 )

```

### Muestreo Cubo - Población Estudiantes {#sec-cubo_estudiantes}

En esta pequeña sección queremos observar la flexibilidad de la técnica del cubo obteniendo una muestra en donde las probabilidades de inclusión son diferentes. En este caso particular serán diferentes pero proporcionales al tamaño de la matrícula. Como vimos con anterioridad, esto produce que los establecimientos con mayor matrícula tengan una mayor chance de ser incluidos en la muestra.

```{r}
#| label: muestra_cubo_matricula

tb = tb |>
filter(matricula >= 1)

pi_matricula = inclusionprobabilities(tb$matricula, n)

tb = bind_cols(tb, as.data.frame(pi_matricula)) |>
relocate("pi_matricula", .after = "rowid")

N = nrow(tb)
n = 300
X = cbind(rep(1, times = N), 
          as.numeric(tb$matricula),
          as.numeric(tb$secciones),
        #  as.numeric(tb$matri_seccion),
         # as.numeric(tb$indice_de_vulnerabilidad), 
          as.numeric(tb$region),
          as.numeric(tb$ambito))
        #  as.numeric(tb$jornada))
  
set.seed(314)

muestra_balanceada_matricula = cube(prob = pi_matricula, 
                                    x = X)

muestra_cubo_matricula = tb[muestra_balanceada_matricula, ] |>
mutate(fpc = sqrt((N-n)/(N-1)),
       pw = N / n)

muestra_cubo_matricula_sv = muestra_cubo_matricula |>
as_survey_design(id = 1,
                 weights = pw,
                # strata = ambito,
                # fpc = fpc,
                 pps = "brewer")

```

```{r}
#| label: tbl-cubo_matricula
#| tbl-cap: Estimaciones con muestra balanceada para población de estudiantes

tbl_cubo_matricula = muestra_cubo_matricula_sv |>
tbl_svysummary(
include = c(matricula, secciones, sondeo_primero, sondeo_segundo, region, ambito),
digits = list(deff = label_style_number(digits = 3),
              sd = label_style_number(digits = 3)),
statistic = list(all_continuous() ~ "{mean} ({sd})",
                all_categorical() ~ "{p}% (n={n_unweighted})")) |>
add_ci()  |>
modify_footnote(all_stat_cols() ~ "Media (DE); % (n sin ponderar)")

tbl_cubo_matricula  

```

```{r}
#| label: tbl-cubos_matricula
#| tbl-cap: 

tbl_pps = read_rds(here("Outputs", "tbl_pps.rds"))

 tbl_merge(
   tbls = list(tbl_cubo_matricula, tbl_pps),
   tab_spanner = c("**Cubo Matrícula**", "**PPS**")
 )

```

## Muestreos bien distribuidos {#sec-well_pread}

Como se dijo en la @sec-cubo en los muestreos balanceados por el método del cubo el esfuerzo está en que los valores de la tendencia central de los estimadores de determinadas variables de la muestra se acerquen a los valores de las covariables existentes como información secundaria, esto es, a los parámetros conocidos de la población. En el muestreo bien extendido (*well spread*) es objetivo es similar pero con una restricción adicional que implica que la distribución de la/s covariable/s de la muestra se acerque a la distribución de la/s covariable/s en la población. El precio de esta mejora es que se debe conocer la distribución de esas variables en la población algo que nunca habían requerido los diseños anteriores. En el caso particular de la distribución espacial el diseño exige la introducción de las coordenadas de cada miembro de la población y no solo el promedio poblacional de ellas.

En este contexto cobra importancia el ejemplo inicial de la @sec-cubo en donde se usaron covariables espaciales. Allí, de manera intuitiva, se asoció que una muestra bien distribuida es una muestra balanceada. Esta afirmación, útil como un primera aproximación, es verdadera pero su inversa no. En otras palabras, toda muestra balanceada no es bien distribuida, pero toda muestra bien distribuida sí es una muestra balanceada.

A continuación trabajaremos con los misma muestra balanceada de colegios de la sección anterior pero le agregaremos la condición de que esa muestra *también* sea bien distribuida en los valores de las coordenadas geográficas. Para eso primero agregaremos las coordenadas a la base de los establecimientos.

```{r}
#| label: coordenadas

coordenadas = read_xlsx(here("Inputs", "Nómina de establecimientos 20241020.xlsx")) |>
select(latitud, longitud, clave)
```

```{r}
#| label: add_coordenadas

tb = tb |>
left_join(coordenadas, by = "clave") |>
filter(!is.na(latitud))|>
filter(!is.na(longitud))

```

Agregadas las coordenadas ahora se puede aplicar la técnica del cubo con el adicional que el balanceo no sólo se realice por los valores de tendencia central de la sección anterior, sino también con los valores de dispersión de las coordenadas de los establecimientos.

En cierto sentido, la inclusión de las variables "Ámbito" y "Región" en el diseño balanceado (@sec-cubo_colegios) ya mejoraban la distribución geográfica o espacial de la muestra (con respecto a una muestra de azar simple) pero lo hacían focalizándonse en sus valores de tendencia central. Los valores de las coordenadas permiten una información de un grano más fino sobre la distribución espacial de la muestra. En efecto, al usarse esta última información en un diseño bien distribuido se aprecia una leve mejora en los valores que tienen una fuerte influencia espacial (p.e "Ambito" y "Región").

```{r}
#| label: muestreo_well_spread

N = nrow(tb)
n = 300
X = cbind(rep(1, times = N), 
          as.numeric(tb$matricula),
          as.numeric(tb$secciones),
        #  as.numeric(tb$matri_seccion),
         # as.numeric(tb$indice_de_vulnerabilidad), 
          as.numeric(tb$region),
          as.numeric(tb$ambito))
        #  as.numeric(tb$jornada))
pi_colegio = rep(n / N, times = N)

xy = cbind(tb$latitud, tb$longitud)

set.seed(314)

muestra_weel_spread = lcube(Xbal = X, 
                            Xspread = xy , 
                            prob = pi_colegio)

muestra_well_spread = tb[muestra_weel_spread,] |>
mutate(pw = N/n,
       fpc = sqrt((N-n)/(N-1)))

muestra_well_spread_sv = muestra_well_spread |>
as_survey_design(id = 1,
                 weights = pw,
                 fpc = fpc)

write_rds(muestra_well_spread_sv,
          here("Outputs", "muestra_well_spread_sv.rds"))
```

```{r}
#| label: tbl-well_spread
#| tbl-fig: sdvdsvv
 
tbl_well_spread = muestra_well_spread_sv |>
tbl_svysummary(
include = c(matricula, secciones, sondeo_primero, sondeo_segundo, region, ambito),
digits = list(deff = label_style_number(digits = 3),
              sd = label_style_number(digits = 3)),
statistic = list(all_continuous() ~ "{mean} ({mean.std.error})",
                all_categorical() ~ "{p}% (n={n_unweighted})")) |>
add_ci()  |>
modify_footnote(all_stat_cols() ~ "Media (DE); % (n sin ponderar)")

write_rds(tbl_well_spread,
          here("Outputs", "tbl_well_spread.rds"))

tbl_merge(
   tbls = list(tbl_well_spread, tbl_cubo_colegios, tbl_pob_param),
   tab_spanner = c("**Well Spread**", "**Cubo colegios**", "**Pob. Colegios**")
 )  


```

En ciencias sociales, la mejora de la distribución espacial de una muestra no es un mejora cualquiera. Es una mejora muy interesante porque también ayuda a controlar, una serie de otras variables que se pueden presumir asociadas al espacio pero no fácilmente accesibles de forma empírica o, por lo menos, no accesible en términos de parámetros poblacionales para el momento del diseño de una muestra. Expresado en jerga metodológica, este tipo de mejoras ayudan a controlar una serie de variables extrañas haciendo que dejen de ser variables perturbadoras [@kish1987].

De todos modos, en este caso particular es razonable suponer que la ubicación de los establecimientos guarda relación con la ubicación de los estudiantes y, más en general, con la distribución de las personas.

```{r}
#| label: fig-mapa_well_spread

tb = tb |>
st_as_sf(coords = c("longitud", "latitud"),
         dim = "XY",
         sf_column_name = "geom_escuela",
         crs = 4326)

muestra_well_spread = muestra_well_spread |>
st_as_sf(coords = c("longitud", "latitud"),
         dim = "XY",
         sf_column_name = "geom_escuela",
         crs = 4326)

tmap_mode("view")

fig_well_spread = tm_basemap(server = "CartoDB.Positron",
           alpha = 0.5) +
tm_shape(tb,
         name = "Población") +
tm_dots(fill_alpha = 0.20,
        fill = "black") +
tm_shape(muestra_well_spread,
         name = "Muestra well spread") +
tm_dots(fill_alpha = 0.9,
        fill = "blue")

fig_well_spread 

```

[^cubo-1]: El mismo fue adaptado del libro "Spatial sampling with R" [@brus2022].

[^cubo-2]: Por ejemplo, las variables "sondeo_primero" y "sondeo_segundo" podrían ser opciones como covariablesc (siempre igual dependiendo que se quiera investigar) pero tienen una alta tasa de no respuesta (+ de 550 casos). Para peor, al menos desde el punto de vista de la población de los establecimientos, estas no respuestas se concentran en establecimientos con una matrícula de menos de 10 estudiantes. Esto genera un problema muestral porque los casos que integran la muestra (p.e. Ambito Urbano) son diferentes a los que no integran (p.e. Ambitos Rurales). En otras palabras, la no respuesta no es aleatoria.
