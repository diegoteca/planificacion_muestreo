## La domesticación del azar como medio para lograr muestras (aproximadamente) representativas

Si ser muy profundos en cuanto a la teoría del muestreo o en cuanto a su justificación más académica en lo que sigue se intenta recordar que sucede si se realizan muestras aleatorias dentro de una población. Este enfoque tiene mucho que ver con lo que se suele denominar "*Design Based Sample"* en la literatura sobre muestreo*.* Básicamente, en línea con la clasificación de Neyman anteriormente utilizada, son muestras que ponen énfasis en el proceso aleatorio de la selección de los casos. Es una escuela clásica dentro del muestro y tiene muchas subvariantes. Algunas de ellas las veremos más adelante pero ahora nos concentraremos en la parte que tienen en común toda ellas. Para eso vamos a simular que hacemos muchas muestras aleatorias simples sobre una población imaginaria no muy grande (\<2000). Primero haremos, o más bien repetiremos, muestras relativamente pequeñas y luego haremos muestras algo más grandes.

Para tener una mejor experiencia de este simulador es aconsejable su ejecución a través de este [link](https://planificacion-muestreo.netlify.app/simulador_teorema_limite_central.html).

<iframe width="100%" height="500" src="https://diegoteca.com.ar/SimuladorTeoremaLimiteCentral.html" title="Webpage example">

</iframe>

Con este programa podemos jugar de varias formas. Aquí nos interesa las siguientes.

1.  En primer lugar ver que pasa, en los términos de la figura "datos acumulativos de las muestras" cuando realizamos muchas muestras sobre una misma población (p.e. Población = "Opción 3"). Como veremos, estas distribuciones, en especial si la muestra contiene más de 30 casos, converge hacia un patrón de distribución "normal". Lo interesante es que esta distribución emerge, con mayor o menor rapidez, de manera independiente de la forma de la población (Ver punto 2). También se puede probar escogiendo diferentes tamaños de las muestras (p.e. Tamaño de la muestra = 30 y 200).

2.  Por otro lado se puede probar que sucede si, se hace el ejercicio anterior en diferentes poblaciones (p.e. con Población = "Opción 6"). Como se observará siempre se obtiene una distribución "normal" aunque en mayor tiempo y con una mayor varianza.

## Población

Como se anticipó en la introducción, nuestra **población** será una población de establecimientos educativos de gestión estatal de nivel primario. Cada uno de los integrantes de esta población se pueden considerar como **unidades de selección**, el subconjunto finalmente seleccionado será la **muestra** y la cantidad de los miembros seleccionados será el **tamaño de la muestra**. En este caso, como se observa en @tbl-escuelas, se tiene información variada sobre cada una de las escuelas. Como veremos más adelante, tener más información sobre las unidades de selección puede ayudar para la efectiva realización de diferentes diseños muestrales. Algunos de esos diseños servirán cuando el objetivo sea tener una muestra de escuelas (muestreos de una sola etapa) y otros, generalmente más complejos, podrán servir como un primer paso para luego realizar una muestra a estudiantes, directivos, etc. (muestreo polietápicos).

```{r}
#| label: librerias_azar

library(here)
library(readxl)
library(janitor)
library(tidyverse)
library(gt)
library(sampling)
library(gtsummary)
library(infer)
library(patchwork)
library(srvyr)
library(survey)
library(cardx)
library(downloadthis)

i_am("azar.qmd")

theme_gtsummary_language(
language = "es",
decimal.mark = ",",
big.mark = ".")
```

```{r}
#| label: tbl-escuelas
#| tbl-cap: "Información de la base de escuelas"

levels_region = c("01", "02", "03", "04", "05", "06", "07",
                  "08", "09", "10", "11", "12", "13", "14",
                  "15", "16", "17", "18", "19", "20", "21",
                  "22", "23", "24", "25")

base = read_xlsx(here("Inputs", "base_escuelas_primaria.xlsx")) |>
clean_names() |>
mutate(ambito = as_factor(ambito),
       region = as_factor(region),
       region = fct_relevel(region, levels_region))

base |>
slice_head(n = 3) |>
gt()

download_this(base,
              output_name = "base_escuelas_primarias",
              output_extension = ".xlsx",
              button_label = "Descargar Base")

write_rds(base,
          here("Outputs", "base.rds"))
```

Como puede observarse se trata de una base de escuelas en el sentido que en cada fila hay un establecimiento diferente que contiene una serie de propiedades de los mismos en cada una de las columnas. Algunas de esas propiedades se podrían considerar como intrínsecas de cada escuela (clave, región, ámbito, etc.), otras pueden considerarse como propiedades agregadas de los establecimientos en el sentido que devienen de agregaciones de los estudiantes que son parte de cada escuela (p.e. prueba_x) o de los directivos de los mismos (p.e. direct_x). Esta distinciones son importantes cuando se quiere realizar una muestra porque esto indica límites y posibilidades sobre a qué población se puede realizar una "buena" muestra desde este archivo. En este contexto, la información de este archivo es particularmente buena para realizar una muestra de colegios pero quizá no tan apropiada para realizar una muestra de estudiantes o directivos...al menos si se lo compara, respectivamente, con tener acceso a lista de estudiantes o directivos con el agregado del dato de la escuela. Como veremos más adelante, si se tiene en mente este último punto es posible minimizar algunos de esos problemas aplicando algunas estrategias (p.e. seleccionar pocos estudiantes de cada colegio seleccionado) o, de forma más explícita, hacer una muestra proporcional al tamaño de la matrícula de cada establecimiento.[^azar-1]

Por ahora trabajaremos con este archivo para realizar diferentes tipos de muestras de establecimientos educativos. Un plus pedagógico de esta estrategia es que vamos a tener a mano los valores de las estimaciones de las diferentes muestras que se vayan realizando y los respectivos valores de los parámetros poblaciones para comparar resultados. Algunos de esos valores poblacionales se podrán considerar como información secundaria en el sentido que el interés de la muestra no es estimar esos parámetros. Otros de esos valores se los podrá considerar como los parámetros a estimar en la muestra. Esta última situación no es la usual porque si ya se tiene el parámetro poblacional no es necesario la realización de una muestra para su estimación.

Dentro de los parámetros poblacionales vamos a calcular los siguientes:

-   Matrícula

-   Secciones

-   Sondeo primero

-   Sondeo segundo

-   Región

-   Ámbito

Algunas de las variables anteriores son categóricas (región, ámbito) y otras no. Vamos a ver que esto importa porque no es lo mismo estimar un parámetro continuo que uno categórico. Dentro de estos últimos tampoco es lo mismo estimar una variable con 25 categorías (p.e. región) que una variable categórica de 3 categorías (p.e. ámbito).

En la @tbl-parametros_base puede observarse algunos de los valores de estos parámetros. Para el caso de las variables continuas (Matrícula, Secciones, sondeo primero, sondeo segundo) se ha calculado la media junto con los valores del primer y tercer cuartil. En el caso de las variables categóricas (región, ámbito) se han calculado los respectivos porcentajes de cada categoría. Esta distinción es importante porque mientras algunas muestras se esfuerzan por estimar medidas de tendencia central, otras se esfuerzan por estimar medidas de dispersión central y otras intentan hacer ambos tipos de estimaciones. Otra distinción importante es la anteriormente mencionada sobre la población que se quiera muestrar. Por ejemplo, el valor de la media del primer sondeo puede ser útil para estimar si la media de la **población de colegios** arroja un valor similar que la media de la/s muestra/s realizada/s de esos colegios pero no hay que olvidar que esos datos, si que quiere referir a la **población de estudiantes**, habría que ponderarlos por la matrícula de cada colegio, esto es, habría que calcular su media ponderada.

```{r}
#| label: tbl-parametros_base
#| tbl-cap: "Valores poblacionales de las escuelas"

base_toy = base |>
select(clave, matricula, secciones, sondeo_primero, sondeo_segundo, region, ambito) 

tbl_pob_param = base_toy |>
tbl_summary(include = !clave,
      statistic = list(
      all_continuous() ~ "{mean}",
      all_categorical() ~ "{p}% ({n})"),
digits = list(everything() ~ c(1,0)))

tbl_pob_param

write_rds(tbl_pob_param,
          here("Outputs", "tbl_pob_param.rds"))
```

Estos parámetros "conocidos" van a tener 2 funciones en este taller. Por un lado nos van a servir para cotejar, *ex-ante,* la media de las medias muestrales realizadas con azar simple y, por otro lado, nos pueden servir, *ex-post*, para mejorar las muestras concretas efectivamente obtenidas. Esto último, más allá de las técnicas específicas que se utilicen, es importante por lo siguiente:

Las muestras que se hacen en la realidad son "únicas" o "individuales" en el sentido que no se repiten. En cambio, una buena parte de la teoría del muestreo supone una distribución de muestras (como las simulaciones anteriores en donde se realizaban varias muestras de una misma población). La mayoría de la veces el investigador que sale a campo dispone de sólo una muestra y el objetivo es que "esa" muestra (y no cualquier otra posible) sea de las mejores y no de las peores. En este sentido, es útil tener herramientas que permitan saber si la muestra es de las buenas o de las malas y, si se trata de este último caso, como mejorarlas.

## Muestreo por azar simple {#sec-azar_simple}

Dentro de los métodos aleatorios el método del azar simple (*random sampling*) es un método tradicional y particularmente útil desde un punto de vista pedagógico para comenzar ya que muchos otros métodos son variaciones (usualmente más complejas) de este. El método del azar simple es el que intuitivamente se ha utilizado en la simulación anterior.

Desde una perspectiva amplia, en la actualidad se podría afirmar que este método de muestreo se encuentra en el medio de un continuo de situaciones en cuando al grado de información exigida para su realización. Lo "único" que pide es una lista de "contactos" de la población que se quiere analizar. La razón por la que "único" se encuentra entre comillas es la siguiente: La necesidad de la una lista puede ser algo exigente en algunas investigaciones (p.e. poblaciones invisibles) aunque algo insuficiente para otras (p.e. diseños con muestras estratificadas). La idea de "contacto" es algo polisémica pero aquí apunta a que el caso seleccionado se pueda contactar de alguna forma (p.e. dirección de domicilio, mail, celular, etc.) para realizarle las observaciones/mediciones correspondientes.

A continuación vamos a realizar unas 1000 muestras de 300 casos cada una sobre el total de las 4168 escuelas. Esto es una relación entre el tamaño de la población y la muestra de casi el 14%. Hacemos esta cantidad de muestras para observar la distribución de los valores de las medias de cada muestras y ver si sucede algo similar a lo encontrado en el simulador anterior. Para facilitar la comparación lo haremos sólo con las variables numéricas y dejaremos de lado las categóricas como Ámbito y Región. El resultado de estas simulaciones se puede observar en la @tbl-medias_muestrales_azar_simple.

```{r}
#| label: azar_simple_rep

set.seed(314) 

muestras_azar_simple = base_toy |>
rep_slice_sample(n = 300,
                 replace = FALSE,
                 reps = 1000)  

```

```{r}
#| label: tbl-medias_muestrales_azar_simple
#| tbl-cap: "Medias de las medias muestrales"

tbl_medias_muestrales = muestras_azar_simple |>
group_by(replicate) |>
summarise(matricula = mean(matricula, na.rm = TRUE),
          secciones = mean(secciones, na.rm = TRUE),
          sondeo_primero = mean(sondeo_primero, na.rm = TRUE),
          sondeo_segundo = mean(sondeo_segundo, na.rm = TRUE)) |>
tbl_summary(include = !replicate,
            statistic = list(
      all_continuous() ~ "{mean} ({sd})"))

tbl_medias_muestrales
```

Como se puede comparar entre @tbl-parametros_base y @tbl-medias_muestrales_azar_simple los valores entre los parámetros poblacionales y la media de las estimaciones muestrales coincide. No sólo eso. También podemos chequear que la distribución de esas medias sigue una distribución aproximadamente normal. Esto es lo que precisamente hacemos en la @fig-medias_muestrales_azar_simple .

```{r}
#| label: fig-medias_muestrales_azar_simple
#| fig-cap: "Distribución de las medias muestrales"

fig_medias_muestrales_matricula = muestras_azar_simple |>
group_by(replicate) |>
summarise(matricula = mean(matricula, na.rm = TRUE)) |>
ggplot(aes(matricula)) +
geom_histogram() + 
xlab("Matrícula") +
ylab("Cantidad de muestras")

fig_medias_muestrales_secciones = muestras_azar_simple |>
group_by(replicate) |>
summarise(secciones = mean(secciones, na.rm = TRUE)) |>
ggplot(aes(secciones)) +
geom_histogram() + 
xlab("Secciones") +
ylab("Cantidad de muestras")

fig_medias_muestrales_sondeo_primero = muestras_azar_simple |>
group_by(replicate) |>
summarise(sondeo_primero = mean(sondeo_primero, na.rm = TRUE)) |>
ggplot(aes(sondeo_primero)) +
geom_histogram() + 
xlab("Primer Sondeo") +
ylab("Cantidad de muestras")

fig_medias_muestrales_sondeo_segundo = muestras_azar_simple |>
group_by(replicate) |>
summarise(sondeo_segundo = mean(sondeo_segundo, na.rm = TRUE)) |>
ggplot(aes(sondeo_segundo)) +
geom_histogram() + 
xlab("Segundo Sondeo") +
ylab("Cantidad de muestras")


fig_medias_muestrales_matricula +
fig_medias_muestrales_secciones +
fig_medias_muestrales_sondeo_primero +
fig_medias_muestrales_sondeo_segundo
```

En la figura anterior se observa que la distribución de las 1000 muestras que tomamos, si bien se aproximan, no son idénticas a una distribución normal. Seguramente, si haríamos más muestras nos acercaríamos aún más a una distribución muestral pero quizá este ejemplo baste para explicitar el siguiente punto. Si haríamos muchas muestras vamos a saber con cierta seguridad que la media de las muestras será aproximadamente similar al parámetro poblacional pero ¿Qué sucede si sólo tomamos una sola muestra? Nuevamente ¿Cómo sabemos si nuestra (única) muestra es de las buenas o de las malas? ¿Cómo sabemos que nuestra muestra no es alguna de las que están en el extremo izquierdo o derecho de la @fig-medias_muestrales_azar_simple ?

Ahí es donde entra la ayuda de las librerías específicas. En la introducción se había comentado sobre la existencia de librerías específicas para el análisis de datos muestrales. Estas librerías le van a prestar atención a varios detalles del proceso de selección y nos van a pedir que los explicitemos. Por ejemplo, El tipo de muestras que nos van a interesar generalmente son "sin reemplazo" en el sentido que no queremos que, por ejemplo, un mismo colegio aparezca dos veces seleccionado en una muestra de colegios. También, casi todas las librerías de este estilo, nos van a pedir información de algunos totales de la población para construir ponderadores y otras librerías nos a pedir esos ponderadores utilizarlos en el análisis de los datos. En el caso de una muestra aleatoria simple ese ponderador, al menos en la fase de diseño, suele ser la probabilidad inversa de haber ingresado en la muestra ($N/n$, donde $N$ es el tamaño de la población y $n$ el tamaño de la muestra). En este tipo de diseño el valor del ponderador es el mismo para todas las unidades seleccionadas.

```{r}
#| label: azar_simple

set.seed(314) 

# fpc = ((N-n)/(N-1))1/2

muestra_azar_simple = base |>
slice_sample(n = 300, replace = FALSE) |>
mutate(id = row_number())

n = nrow(muestra_azar_simple)
N = nrow(base)

muestra_azar_simple = muestra_azar_simple |>
mutate(pw = N/n,
       fpc = sqrt((N-n)/(N-1)))

muestra_azar_simple_sv = muestra_azar_simple |>
as_survey_design(ids = id,
                 weights = pw,
                 fpc = fpc)

write_rds(muestra_azar_simple_sv,
          here("Outputs", "muestra_azar_simple_sv.rds"))
```

```{r}
#| label: tbl-azar_simple
#| tbl-cap: "Estimaciones con azar simple"

tbl_azar_simple = muestra_azar_simple_sv |>
tbl_svysummary(
include = c(matricula, secciones, sondeo_primero, sondeo_segundo, region, ambito),
statistic = list(all_continuous() ~ "{mean} ({mean.std.error})",
                all_categorical() ~ "{p}% (n={n_unweighted})"),
digits = list(all_continuous() ~ c(1),
              all_categorical() ~ c(1,0))) |>
add_ci()

write_rds(tbl_azar_simple,
          here("Outputs", "tbl_azar_simple.rds"))

tbl_merge(
  tbls = list(tbl_azar_simple, tbl_pob_param),
  tab_spanner = c("**Azar simple**", "**Parámetro Pob.**")
)


```

Ahora que estamos analizando sólo una muestra podemos empezar a ver algunas distancias entre los parámetros poblaciones y las estimaciones que surgen de la muestra. Esto es especialmente más notorio en los casos de las categorías menos difundidas de las variables categóricas como puede ser algunas de las regiones.

## Muestreo Sistemático

El muestro sistemático no ofrece muchas diferencias apreciables de cálculo con el azar simple aunque tiene un diferencia logística importante. No es necesario tener en el momento del diseño una lista centralizada de "contactos" a quien seleccionar. Esto hace que el muestreo sistemático, especialmente en muestras polietápicas, sea un buen candidato a aplicar en las últimas instancias de selección en donde cada encuestador, de manera descentralizada, sí tiene acceso, *in situ*, a esa información. Es importante, de todos modos, suponer que la lista en cuestión no esconda un sesgo particular en su orden o, ante esta presuposición, poder reordenarla bajo algún criterio que fuerce el azar.

Como ejemplo podemos analizar la siguiente situación. Se quiere realizar una muestra de estudiantes pero a) no se cuenta con información nominal en el momento del diseño de la muestra pero b) sí se cuenta con una buena base de los colegios y c) se asume que dentro de cada colegio sí existe acceso a una lista de contactos de los estudiantes. En este contexto, se puede sortear una cantidad de colegios en una primera etapa y luego, en una segunda etapa, se puede indicar al directivo, encuestador, etc. de cada escuela seleccionada que, una vez con acceso a la lista de estudiantes, seleccione una $X$ cantidad de los mismos. Para realizar esa última selección el proceso será sortear al primer estudiantes, seleccionarlo y luego, desde allí, saltar $K$ estudiantes para seleccionar al segundo estudiante y así sucesivamente. En general, $K$ representa el cociente entre el tamaño de la población a seleccionar $N$ como el tamaño de la lista de estudiantes del colegio seleccionado y el tamaño de la muestra $n$ como la cantidad de estudiantes que se quiere seleccionar de esa lista.

$$
K = \frac{N}{n}
$$

Siguiendo este ejemplo, supongamos que el encuestador tenga que elegir 5 estudiantes de una lista de 50. En ese caso se podría aplicar siguiente código:

```{r}
#| label: sistematico

set.seed(314)

n = 5
lista_estudiantes = as_tibble(c(1:50))
N = 50 
k = ceiling(N/n) # K = 10

# Se sortea el primer estudiante

inicio_sistematico = sample(n, size = 1) 

# Y luego se continua de manera sistemática

sorteo = seq(from = inicio_sistematico, 
             by = k , 
             length.out = n)

muestra_sistematica = lista_estudiantes[sorteo, ]
```

Cambiando lo que haya que cambiar, el código anterior también se podría aplicar si se quiere utilizar para seleccionar los 300 establecimientos que antes se habían seleccionado con el diseño del azar simple.

## Muestreo Estratificado

El muestreo estratificado es un tipo de muestreo que se realiza en base a estratos que, en principio, sean parecidos en su interior y diferentes entre ellos. Una característica distintivas de los estratos es que son discretos, esto es, pueden tener a lo sumo un orden entre los diferentes estratos, pero sus límites son puntuales más que continuos.

Si se recuerda los comentarios realizados en la introducción, cuanto menos heterogeneidad exista entre los unidades a seleccionar menor es el problema de la representatividad. Esto es precisamente lo que intenta aprovechar la idea del muestreo estratificado. En el extremo, si todos los miembros de cada estrato son iguales entre sí y los tamaños de cada estrato también son iguales entre sí, sólo habría que seleccionar a un caso por estrato y sólo con eso se tendría una muestra representativa de la población. Si los tamaños de los estratos fueran diferentes también se podría seleccionar un caso por estrato pero la condición para que esta muestra sea representativa es que luego se incluyan ponderadores diferentes para cada estrato de la muestra en función de la inversa de la probabilidad de entrar en la muestra.

Para que el muestreo estratificado produzca ventajas (en comparación con el azar simple) los estratos deben tener una heterogeneidad interna menor a la heterogeneidad del conjunto de la población aunque aquella se encuentre lejos del ejemplo extremo del párrafo anterior. Los estratos son variables discretas que conforman subpoblaciones mutuamente excluyentes y exhaustivas de toda población aunque se pueden construir los mismos en función de datos categóricos, continuos (p.e. agrupaciones de años de antigüedad) o espaciales (p.e. Regiones). En una base de datos educativa puede haber muchas variables que pueden ser considerados como estratos. En este caso, a modo de ejemplo, nos quedaremos con "Ámbito" que posee 3 categorías que asumimos, como diría Platón en el Fedro, que cortan la realidad por sus articulaciones naturales [@platón2002, pag. 55]. Por otro lado, utilizar "Ámbito" como estrato tiene otra virtud pedagógica que deviene de la diferente distribución de cada categoría. Esto lo hace un buen candidato para mostrar la utilidad del muestreo estratificado en su versión proporcional y no proporcional ya que la categoría "Rural Agrupado" posee un menor porcentaje de casos y, a igualdad de otras condiciones, eso dificulta su posterior análisis.

Usualmente los estratos se construyen en base a antecedentes teóricos pero nada impide que los estratos sean constructos estadísticos con una significado no muy claro como los que se pueden producir luego de un análisis de clusters. Tampoco la técnica tiene una limitación en cuanto a la cantidad de categorías.

|   | Estratificado Proporcional | Estratificado no Proporcional |
|------------------------|------------------------|------------------------|
| **Estratos Teóricos** | Estrato teórico (p.e. Ámbito) con probabilidad proporcional | Estrato teórico (p.e. Ámbito) con probabilidad no proporcional |
| **Estratos Empíricos** | Estrato estadístico con probabilidad proporcional | Estrato estadístico con probabilidad no proporcional |

### Estratos teóricos con asignación proporcional

En este subtipo de muestreo estratificado utilizaremos la variable "Ámbito" como estrato y respetaremos, aproximadamente, la distribución que ese estrato posee en la población. Decimos aproximadamente porque aquí siempre existe un factor de redondeo que deviene de la necesidad de realizar la muestra sobre una cantidad de casos discretos. Esta última necesidad hace que, al igual que cuando se intenta respetar las proporciones de los votos de una elección para la renovación de bancas de la Cámara de Diputados, casi siempre existan pequeñas diferencias entre las proporciones poblacionales y las muestrales.

```{r}
#| label: estratificado_proporcional

set.seed(314)

n = 300
N = nrow(base)

base_toy = base_toy |>
arrange(ambito) |>
mutate(id = row_number())

datos_estratos = base_toy |>
tabyl(ambito) 

size_strata = datos_estratos |>
select(percent) |>
mutate(size_strata = round(percent * n)) |>
select(size_strata) |>
pull()

# Chequeo la suma de los estratos por el redondeo
test_sum = sum(size_strata)

# Como da 299 le sumo 1 caso al primer estrato

size_strata[1] = size_strata[1] + 1

muestra_estrat_teo_prop = sampling::strata(base_toy,
stratanames = c("ambito"),
size = size_strata,
method = "srswor") |>
rename(id = ID_unit) |>
select(!ambito) |>
left_join(base_toy, by = "id") |>
left_join(datos_estratos, by = "ambito") |>
group_by(Stratum) |>
mutate(estrato_n = n(),
       fpc = sqrt((n-estrato_n)/(n-1))) |>
ungroup() |>
mutate(weight = n / estrato_n)
 

```

Seleccionada la muestra ahora le especifico los detalles del diseño mediante la librería survey o srvyr.

```{r}
#| label: estratificado_propocional_sv

muestra_estrat_teo_prop_sv = muestra_estrat_teo_prop |>
as_survey_design(id = 1,
                 weights = weight,
                 strata = ambito,
                 fpc = fpc)

```

Y luego realizo la @tbl-estratificado_teo_prop con la información de algunas variables y esa misma tabla lo comparo con los valores de la @tbl-azar_simple que refería al diseño con azar simple.

```{r}
#| label: tbl-estratificado_teo_prop
#| tbl-cap: "Tablas comparativas entre resultados azar simple y estratificado"

tbl_estrat_teo_prop = muestra_estrat_teo_prop_sv |>
tbl_svysummary(
include = c(matricula, secciones, sondeo_primero, sondeo_segundo, region, ambito),
statistic = list(all_continuous() ~ "{mean} ({mean.std.error})",
                all_categorical() ~ "{p}% (n={n_unweighted})"),
digits = list(all_continuous() ~ c(1),
              all_categorical() ~ c(1,0))) |>
add_ci() 

tbl_merge(
  tbls = list(tbl_estrat_teo_prop, tbl_azar_simple),
  tab_spanner = c("**Estratificado P.**","**Azar simple**")
) |>
modify_footnote(all_stat_cols() ~ "Media (DE); % (n sin ponderar)")
```

### Estratos teóricos con asignación no proporcional

En el tipo de diseño anterior hubo una variable (Ámbito) que se usó para estratificar la muestra. En ese caso, salvo variaciones menores debido a los factores de redondeo antes comentados, las proporciones de la muestra respetan las proporciones poblacionales. Eso es lo que precisamente se intenta modificar con el muestreo teórico con una asignación no proporcional. Usualmente, la idea que está detrás de esta estrategia es poder incrementar la cantidad de casos en aquellas categorías de los estratos que tienen una escasa de cantidad de casos para luego usarlos como dominios de estimación[^azar-2]. Si se respeta la proporción y existen categorías que poseen una distribución muy baja, nos vamos a quedar con pocos casos y con un alto error estándar en esos análisis. Aquí, para extremar esta lógica, vamos a realizar una muestra como si las distribución de la variable Ámbito fuera iguales para las sus 3 categorías.

```{r}
n = 300
N = nrow(base)

base_toy = base_toy |>
arrange(ambito) |>
mutate(id = row_number())

datos_estratos = base_toy |>
tabyl(ambito) 

# Acá cambio el código para asignar una misma proporción a todos los estratos

size_strata = datos_estratos |>
select(percent) |>
mutate(size_strata = n / length(levels(base_toy$ambito))) |>
select(size_strata) |>
pull()

# Chequeo la suma de los estratos por el redondeo
test_sum = sum(size_strata)

#size_strata[1] = size_strata[1] + 1

set.seed(314)

muestra_estrat_teo_no_prop = sampling::strata(base_toy,
stratanames = c("ambito"),
size = size_strata,
method = "srswor") |>
rename(id = ID_unit) |>
select(!ambito) |>
left_join(base_toy, by = "id") |>
left_join(datos_estratos, by = "ambito") |>
group_by(Stratum) |>
mutate(estrato_n = n(),
       fpc = sqrt((n-estrato_n)/(n-1))) |>
ungroup() |>
mutate(weight = n / estrato_n)
```

```{r}

muestra_estrat_teo_no_prop_sv = muestra_estrat_teo_no_prop |>
as_survey_design(id = 1,
                 weights = weight,
                 strata = ambito,
                 fpc = fpc)

```

```{r}
#| label: tbl-estratificado_teo_no_prop
#| tbl-cap: "Tablas comparativas entre muestra estraificada proporcional y no propocional"

tbl_estrat_teo_no_prop = muestra_estrat_teo_no_prop_sv |>
tbl_svysummary(
include = c(matricula, secciones, sondeo_primero, sondeo_segundo, region, ambito),
digits = list(deff = label_style_number(digits = 2),
              sd = label_style_number(digits = 3)),
statistic = list(all_continuous() ~ "{mean} ({mean.std.error})",
                all_categorical() ~ "{p}% (n={n_unweighted})")) |>
add_ci() 

tbl_merge(
  tbls = list(tbl_estrat_teo_prop, tbl_estrat_teo_no_prop),
  tab_spanner = c("**Estratificado P**", "**Estratificado no P**")
) |>
modify_footnote(all_stat_cols() ~ "Media (DE); % (n sin ponderar)")
```

## Muestreo por Clusters {#sec-clusters}

El muestreo por cluster es otra manera de aplicar el azar para diseñar muestras. A diferencia del muestreo estratificado en el muestreo por cluster el investigador considera a los cluster como "racimos" de casos que, usualmente, se encuentran cercanos geográficamente pero no necesariamente socialmente o, más en general, no son homogéneos en las variables de estudio. En efecto, la ventaja de este tipo de muestreo es que abarata costos en la ejecución de muestras espacialmente extensas y especialmente si en ese espacio extenso hay numerosos racimos de casos como, por ejemplo, una multitud de pequeños poblados urbanos de 50.000 personas. El precio que usualmente se paga es (a igual cantidad de casos) un aumentoen el error estandard pero, justamente, el quid de la cuestión es que dado la baja del costo unitario de cada caso ahora es posible, con igual presupuesto, agregar más casos a la muestra para bajar la precisión hasta el valor deseado.

## Muestreo Proporcional al tamaño (PPS) {#sec-pps}

Muchas veces, especialmente en diseños polietápicos, se desea que en la primera etapa las unidades de selección sean escogidas en función de alguna variable que sirva como indicador de su tamaño. Esta técnica se suele denominar muestreo proporcional al tamaño (PPS)[^azar-3] y puede considerarse como un caso especial del muestreo por Clusters [@lumley2010, pag. 46]. En el caso de unidades geográficas esa variable podrá ser el tamaño espacial o área (p.e. km^2^) y en variables no espaciales podrá ser la cantidad de personas (p.e. votantes en distritos). En el caso de una muestra de colegios, variables como el tamaño de la matrícula pueden ser buenas candidatas a utilizar en este tipo de muestras. Sin embargo, esto, por definición, va a otorgar una mayor probabilidad de salir en la muestra a los colegios con mayor matrícula y estos pueden poseer características particulares como, por ejemplo, encontrarse abrumadoramente en ámbitos urbanos. De este modo ya podemos intuir que, con respecto a la población de establecimientos, una muestra PPS (sin ponderar) obtendrá como resultado un valor de la matrícula mayor y una sobrerepresentación de los **establecimientos** de ámbito urbano aunque no necesariamente de los **estudiantes** de ámbito urbano. Esto último depende que se haga después de haber realizado la selección primaria.

A pesar de cierta idea intuitiva acerca del objetivo del muestro PPS, su efectiva aplicación (especialmente en muestreos sin reemplazo) tiene sus complejidades a nivel de los algoritmos a utilizar. Esto en parte es algo compartido por todos los muestreos sin reemplazo (versus los con reemplazos) pero aquí está presente la dificultad extra de que las probabilidades de inclusión son diferentes. En efecto, el muesteo PPS puede ser considerado como un tipo de muestreo con probabilidades diferentes (*unequal probabilities*) pero con la particularidad que esas probabilidades diferentes se calculan en función del tamaño de las unidades a seleccionar en primera instancia. A continuación vamos a utilizar un algoritmo que tiene que ver con la idea de "*local pivotal*" que vamos a ver con mayor profundidad cuando veamos las muestras bien dispersas (@sec-well_pread)[^azar-4]

Para visualizar esto vamos primero vamos a construir a realizar 2 ejemplos. Uno en donde se realiza un PPS en donde luego sólo se expande por un igual ponderador y otro en donde a esa misma muestra se la pondera por la probabilidad inversa de haber ingresado en la muestra, esto es, un ponderador que haga pesar menos a aquellos establecimientos con mayor tamaño. Siguiendo con el ejemplo de los colegios, si el proceso es seleccionar los colegios por tamaño y luego realizar un censo (esto es, ninguna muestra) dentro de cada uno de los colegios seleccionados, tanto los colegios como los estudiantes de ámbito urbano se encontrarán sobrerepresentados por lo que este último ponderador puede ser útil.

```{r}
#| label: muestra_pps_one_stage

# Saco los NA de las escuelas sin matrícula

base_toy_pps = base_toy |>
filter(!is.na(matricula)) |>
arrange(desc(matricula))

N = nrow(base_toy_pps)
n = 300
pi = inclusionprobabilities(base_toy_pps$matricula, n)

set.seed(314)

muestra_pps = UPrandompivotal(pik = pi) |>
              as_tibble() |>
rename(muestra_pps = value) |>
bind_cols(base_toy_pps) |>
bind_cols(as.data.frame(pi)) |>
filter(muestra_pps > 0) |>
mutate(fpc = sqrt((N-n)/(N-1)),
       pi = pi,
       pw = N/n)

```

```{r}
#| label: muestra_pps_ponderacion

# En este caso como se trata de un PPS de una sola etapa y la base es de establecimientos id = 1. Si se trataría de una PPS polietápico y se trabajaría con una base de estudiantes el id debería ser la variable que indique el establecimiento.

# En este caso puntual no hay que setear el "weight" y en el fpc (Factor de correción para muestras finitas) debe ir las probabilidades 

# No se construye la variable "weight" porque el diseño no lo necesita.

muestra_pps_sin_ponderar_sv = muestra_pps |>
as_survey_design(id = 1,
                #probs = pi,
                 weights = pw,
                #strata = ambito,
                 fpc = fpc,
                 pps = "brewer")

write_rds(muestra_pps_sin_ponderar_sv,
          here("Outputs", "muestra_pps_sin_ponderar_sv.rds"))

muestra_pps_ponderada_sv = muestra_pps |>
as_survey_design(id = 1,
                probs = pi,
                # weights = pi,
                # strata = ambito,
                 fpc = fpc,
                 pps = "brewer")
```

```{r}
#| label: tbl-pps_ponderadores
#| tbl-cap: "Tablas comparativas entre PPS con ponderador y sin ponderador"

tbl_pps_sin_ponderar = muestra_pps_sin_ponderar_sv |>
tbl_svysummary(
include = c(matricula, secciones, sondeo_primero, sondeo_segundo, region, ambito),
statistic = list(all_continuous() ~ "{mean} ({mean.std.error})",
                all_categorical() ~ "{p}% (n={n_unweighted})"),
digits = list(all_continuous() ~ c(1,2),
              all_categorical() ~ c(1,0))) |>
add_ci() 

tbl_pps_ponderada = muestra_pps_ponderada_sv |>
tbl_svysummary(
include = c(matricula, secciones, sondeo_primero, sondeo_segundo, region, ambito),
statistic = list(all_continuous() ~ "{mean} ({mean.std.error})",
                all_categorical() ~ "{p}% (n={n_unweighted})"),
digits = list(all_continuous() ~ c(1,2),
              all_categorical() ~ c(1,0))) |>
add_ci() 

write_rds(tbl_pps_sin_ponderar,
          here("Outputs", "tbl_pps_sin_ponderar.rds"))
          
write_rds(tbl_pps_ponderada,
  here("Outputs", "tbl_pps_ponderada.rds"))

tbl_merge(
  tbls = list(tbl_pps_sin_ponderar, tbl_pps_ponderada),
  tab_spanner = c("**PPS sin ponderar**", "**PPS ponderada**")
) |>
modify_footnote(all_stat_cols() ~ "Media (EST); % (n sin ponderar)")
```

En efecto, en la @tbl-pps_ponderadores puede observarse que si trabajamos en un PPS sólo expandiendo pero sin ponderar vemos como el valor promedio de la matrícula es alto (529) y que la abrumadora mayoría de los establecimientos seleccionados son del ámbito urbano (95%). Si luego analizamos la muestra ponderada vemos como la mayoría de los valores se acercan a los valores conocidos de la población, especialmente aquellos que refieren a propiedades intrínsecas de los establecimientos como la región y el ámbito. Es interesante también observar que en muchos casos el intervalo de confianza con la muestra ponderada se expande. Esto posiblemente se deba a que el estimador toma nota que al trabajar con la muestra ponderada el error estandar se amplía porque ahora pesan más que antes los casos de menor tamaño y estos son diferentes a los de mayor tamaño, por lo el estimador considera que la muestra pasa a ser más heterogénea.

Si en cambio, luego se realiza un muestro de una cantidad fija (p.e. 10 estudiantes por colegio seleccionado) la muestra de colegios seguirá sobrerepresentando a los colegios del ámbito urbano pero ya no a la población de estudiantes. Esto último justamente puede ser algo buscado explícitamente si se utiliza la selección de los colegios como unidades de selección primarias y luego a los estudiantes como unidades de selección secundaria o final. En otras palabras, se trata de un efecto buscado por diseño, justamente porque ahora el objetivo está puesto en lograr un muestra representativa de la población de estudiantes a través de una población de establecimientos que contiene variables agregadas de los estudiantes.

En este proceso si, por ejemplo, se seleccionarian en primera instancia unos 300 establecimientos, luego se obtendría una muestra final de 3000 estudiantes porque en la segunda instancia se seleccionaron 10 estudiantes por establecimiento. Una virtud práctica de este último ejemplo es que, aparte de reducir costos de logística en comparación a un muestreo por azar simple de un solo paso, otorga un mismo ponderador a cada caso seleccionado lo que facilita algunos análisis posteriores. Esto es un típico ejemplo de muestra compleja en donde la muestra se realiza en más de una etapa y en cada una de ellas se utilizan técnicas diferentes.

En relación con lo anterior y de manera aparentemente paradójica, la muestra PPS sin ponderar estima mejor las variables agregadas como el valor del primer y segundo sondeo que un análisis censal de toda la población de colegios (como se hizo en @tbl-parametros_base). Lo paradógico de esto es que una muestra, esto es, una parte de un todo, logre una mejor acercamiento a un respectivo parámetro poblacional que un censo, esto es, un registro de cada una de la partes del todo. La solución a esta paradoja es entender que la @tbl-parametros_base hace referencia a la población de colegios y, en ese sentido, sus valores son correctos. Ahora bien, si con esos datos (censales, pero de la población de establecimientos) se quiere hacer afirmaciones sobre la población de estudiantes la información de la @tbl-parametros_base no es la más idónea o al menos hay que tratarla de manera diferente. En las variables que se pueden considerar como variables agregadas de estudiantes (p.e. sondeo_primero, sondeo_segundo) más que calcular la media habría que haber calculado la media ponderada por matrícula y ese cálculo sería un mejor estimador de la media de las notas de la población de estudiantes En ese caso, el resultado de ese cálculo sí se podría considerar como un parámetro de la población de estudiantes y contra esos valores se debería comparar las estimaciones del diseño PPS sin ponderar. En este sentido, en la XXXX

```{r}
#| label: tbl_media_ponderada_notas_estudiantes
#| tbl-cap: "Medias de las notas según tipo de muestra y población"

tbl_media_sin_ponderar = base_toy_pps |>
tbl_summary(include = c(sondeo_primero, sondeo_segundo),
            statistic = list(all_continuous() ~ "{mean}"),
            missing = "no")

tbl_media_ponderada = base_toy_pps |>
as_survey_design(ids = id,
                 weights = matricula) |>
tbl_svysummary(include = c(sondeo_primero, sondeo_segundo),
            statistic = list(all_continuous() ~ "{mean}"),
            missing = "no")

tbl_pps_sin_ponderar = muestra_pps_sin_ponderar_sv |>
tbl_svysummary(
include = c(sondeo_primero, sondeo_segundo),
statistic = list(all_continuous() ~ "{mean}"),
            missing = "no")

tbl_merge(
  tbls = list(tbl_pps_sin_ponderar, 
              tbl_media_ponderada, 
              tbl_media_sin_ponderar),
  tab_spanner = c("**PPS sin ponderar**", "**Pob. media ponderada**", "**Pob. media sin ponderar**")) |>
modify_header((all_stat_cols() ~ "")) |>
modify_footnote(everything() ~ NA)

```

```{r}
#| label: tbl-pps
#| tbl-cap: "Tablas comparativas entre PPS y estratificado propocional"
#| eval: false
#| echo: false

tbl_pps = muestra_pps_sv |>
tbl_svysummary(
include = c(matricula, secciones, sondeo_primero, sondeo_segundo, region, ambito),
digits = list(deff = label_style_number(digits = 2),
              sd = label_style_number(digits = 3)),
statistic = list(all_continuous() ~ "{mean} ({mean.std.error})",
                all_categorical() ~ "{p}% (n={n_unweighted})")) |>
add_ci() 

write_rds(tbl_pps,
  here("Outputs", "tbl_pps.rds"))

tbl_merge(
  tbls = list(tbl_pps, tbl_estrat_teo_prop),
  tab_spanner = c("**PPS**", "**Estratificado P**")
) |>
modify_footnote(all_stat_cols() ~ "Media (STD); % (n sin ponderar)")
```

```         
::: {.sectionrefs} :::
```

[^azar-1]: Si el conjunto de los estudiantes (así como los maestros y los directivos) de la provincia hubiera sido sorteado para ingresar a cualquier colegio de la provincia y si todos los colegios tendrían la misma matrícula (así como maestros y directivos), realizar una muestra aleatoria de colegios con el objetivo de realizar una muestra aleatoria de estudiantes (o de maestros y directivos) no sería un mayor problema. El primer criterio tiene que ver con las diferencias de cada colegio y el segundo con el modo de agregar esas diferencias en una muestra cuyo primer paso es la selección de unidades agregadas (colegios) para estimar valores de unidades de selección menores (estudiantes, maestras y directivos).

[^azar-2]: Un dominio o subclase de estimación es una partición de la población o de la muestra sobre la cual se espera realizar inferencias. A veces se usa la denominación que los dominios denotan subpoblaciones (de la población) y las subclases reflejan esas divisiones en la muestra [@kish1980, p. 209]. En cualquier caso es conveniente introducir estos dominios en el diseño de la muestra para poder controlar su tamaño poblacional [@brus2022, cap. 14].

[^azar-3]: La sigla PPS viene de la expresión "**P**robability **P**roportional to **S**ize" que es como se lo conoce en la bibliografía de muestreo.

[^azar-4]: Existen otros algoritmos para realizar un muestreo PPS. Muchos de ellos son algoritmos especializados en probabilidades desiguales (en donde la desigualdad por tamaño sería un caso especial) por lo que muchos de sus nombres suelen empezar con UP (*unequal probabilities*). Algunos son los siguientes: UPtille, UPpivotal, UPpoisson [@tillé2023].
